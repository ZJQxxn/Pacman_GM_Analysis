{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"#!/usr/bin/env python\\n# -*- coding: utf-8 -*-\\n\\n%load_ext nb_black\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"#!/usr/bin/env python\\n# -*- coding: utf-8 -*-\\n\\n%load_ext nb_black\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "%load_ext nb_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# import helper.add_features\\n# import importlib\\n\\n# importlib.reload(helper.add_features)\";\n",
       "                var nbb_formatted_code = \"# import helper.add_features\\n# import importlib\\n\\n# importlib.reload(helper.add_features)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import helper.add_features\n",
    "# import importlib\n",
    "\n",
    "# importlib.reload(helper.add_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\\nfrom IPython.core.debugger import set_trace\\nimport numpy as np\\nimport pandas as pd\\nimport itertools\\nimport seaborn as sns\\nimport sys\\nimport os\\nimport gc\\nimport random\\nimport pickle\\nfrom more_itertools import consecutive_groups\\nfrom ipywidgets import interact, fixed, IntSlider\\nimport subprocess\\n\\n\\nnp.set_printoptions(suppress=True)\\npd.set_option(\\\"display.max_rows\\\", 200)\\nsys.path = sys.path + [\\\"/home/qlyang/Documents/pacman/\\\"]\\n\\nfrom helper.utiltools import eval_df\\nfrom helper.pacmanutils import (\\n    rt_df_filter,\\n    generate_local_4dirs,\\n    relative_dir,\\n    largest_2ndlargest_diff,\\n    to_game,\\n    if_get_nearbean,\\n    assign_category,\\n    combine_pre_post,\\n    add_stats,\\n    add_combine_huntdis,\\n    generate_simulated_local_4dirs,\\n    get_marker,\\n    plot_ghost,\\n    plot_colors_simple,\\n)\\n\\nfrom helper.add_features import add_dis, add_move_dir\\nfrom helper.constant_input import (\\n    OPPOSITE_DIRS,\\n    MAP_INFO,\\n    TURNING_POS,\\n    LOCS_DF,\\n    POSSIBLE_DIRS,\\n    SYMBOLS,\\n    ARRAY,\\n)\\nfrom helper.analysis import status_index\\n\\nfrom ipywidgets import interact, fixed\\nimport ipywidgets as widgets\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\\nfrom IPython.core.debugger import set_trace\\nimport numpy as np\\nimport pandas as pd\\nimport itertools\\nimport seaborn as sns\\nimport sys\\nimport os\\nimport gc\\nimport random\\nimport pickle\\nfrom more_itertools import consecutive_groups\\nfrom ipywidgets import interact, fixed, IntSlider\\nimport subprocess\\n\\n\\nnp.set_printoptions(suppress=True)\\npd.set_option(\\\"display.max_rows\\\", 200)\\nsys.path = sys.path + [\\\"/home/qlyang/Documents/pacman/\\\"]\\n\\nfrom helper.utiltools import eval_df\\nfrom helper.pacmanutils import (\\n    rt_df_filter,\\n    generate_local_4dirs,\\n    relative_dir,\\n    largest_2ndlargest_diff,\\n    to_game,\\n    if_get_nearbean,\\n    assign_category,\\n    combine_pre_post,\\n    add_stats,\\n    add_combine_huntdis,\\n    generate_simulated_local_4dirs,\\n    get_marker,\\n    plot_ghost,\\n    plot_colors_simple,\\n)\\n\\nfrom helper.add_features import add_dis, add_move_dir\\nfrom helper.constant_input import (\\n    OPPOSITE_DIRS,\\n    MAP_INFO,\\n    TURNING_POS,\\n    LOCS_DF,\\n    POSSIBLE_DIRS,\\n    SYMBOLS,\\n    ARRAY,\\n)\\nfrom helper.analysis import status_index\\n\\nfrom ipywidgets import interact, fixed\\nimport ipywidgets as widgets\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "from more_itertools import consecutive_groups\n",
    "from ipywidgets import interact, fixed, IntSlider\n",
    "import subprocess\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "sys.path = sys.path + [\"/home/qlyang/Documents/pacman/\"]\n",
    "\n",
    "from helper.utiltools import eval_df\n",
    "from helper.pacmanutils import (\n",
    "    rt_df_filter,\n",
    "    generate_local_4dirs,\n",
    "    relative_dir,\n",
    "    largest_2ndlargest_diff,\n",
    "    to_game,\n",
    "    if_get_nearbean,\n",
    "    assign_category,\n",
    "    combine_pre_post,\n",
    "    add_stats,\n",
    "    add_combine_huntdis,\n",
    "    generate_simulated_local_4dirs,\n",
    "    get_marker,\n",
    "    plot_ghost,\n",
    "    plot_colors_simple,\n",
    ")\n",
    "\n",
    "from helper.add_features import add_dis, add_move_dir\n",
    "from helper.constant_input import (\n",
    "    OPPOSITE_DIRS,\n",
    "    MAP_INFO,\n",
    "    TURNING_POS,\n",
    "    LOCS_DF,\n",
    "    POSSIBLE_DIRS,\n",
    "    SYMBOLS,\n",
    "    ARRAY,\n",
    ")\n",
    "from helper.analysis import status_index\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def set_landcolor(landscape_colors, landscape=True, land=None):\\n    if landscape:\\n        sns.set_palette(landscape_colors.values())\\n    else:\\n        if land == \\\"straight\\\":\\n            sns.set_palette(plt.cm.Reds(np.linspace(0.3, 1, 4)))\\n        if land == \\\"L-shape\\\":\\n            sns.set_palette(plt.cm.Blues(np.linspace(0.3, 1, 4)))\\n        if land == \\\"fork\\\":\\n            sns.set_palette(plt.cm.Greens(np.linspace(0.3, 1, 4)))\\n        if land == \\\"cross\\\":\\n            sns.set_palette(plt.cm.Wistia(np.linspace(0.3, 1, 4)))\\n\\n\\ndef extend_df_overlap(df_total, condition, data_type=\\\"simulated\\\"):\\n    if data_type != \\\"simulated\\\":\\n        df_overlap = pd.read_pickle(\\n            \\\"../constants/df_overlap_\\\" + \\\"omega\\\" + \\\".pkl\\\"\\n        ).append(pd.read_pickle(\\\"../constants/df_overlap_\\\" + \\\"patamon\\\" + \\\".pkl\\\"))\\n    else:\\n        df_overlap = pd.read_pickle(\\\"../constants/df_overlap_simulated.pkl\\\")\\n    df_filter = df_total.loc[\\n        condition,\\n        [\\\"file\\\", \\\"index\\\", \\\"next_pacman_dir_fill\\\", \\\"pacmanPos\\\", \\\"pacman_dir_fill\\\",],\\n    ]\\n    df_overlap = (\\n        df_overlap.assign(\\n            local_4dirs_diff=largest_2ndlargest_diff(df_overlap),\\n            largest_dir=df_overlap.eq(df_overlap.max(1), axis=0)\\n            .stack()\\n            .replace({False: np.nan})\\n            .dropna()\\n            .reset_index()\\n            .groupby([\\\"file\\\", \\\"index\\\"])\\n            .apply(lambda x: list(x.local_feature_dir)),\\n        )\\n        .reset_index()\\n        .merge(df_filter, on=[\\\"file\\\", \\\"index\\\"], how=\\\"left\\\",)\\n        .merge(MAP_INFO[[\\\"NextNum\\\", \\\"pos\\\"]], left_on=\\\"pacmanPos\\\", right_on=\\\"pos\\\")\\n        .drop(columns=[\\\"pos\\\"])\\n    )\\n    return df_overlap\\n\\n\\ndef intersect_cnt(df, col1, col2):\\n    df[\\\"intersect_cnt\\\"] = df.apply(\\n        lambda x: len(set(x[col1]) & set(x[col2]))\\n        if not isinstance(x[col1], float) and not isinstance(x[col2], float)\\n        else np.nan,\\n        1,\\n    )\\n    return df\\n\\n\\ndef add_possible_dirs(df_total):\\n    for w in [\\\"1\\\", \\\"2\\\"]:\\n        df_total = (\\n            intersect_cnt(\\n                df_total.reset_index()\\n                .merge(\\n                    POSSIBLE_DIRS, left_on=\\\"pacmanPos\\\", right_on=\\\"p_choice\\\", how=\\\"left\\\"\\n                )\\n                .set_index(\\\"level_0\\\"),\\n                \\\"level_1\\\",\\n                \\\"ghost\\\" + w + \\\"_wrt_pacman\\\",\\n            )\\n            .sort_index()\\n            .rename(columns={\\\"intersect_cnt\\\": \\\"intersect_cnt\\\" + w})\\n        )\\n        df_total.loc[\\n            ~df_total[\\\"ghost\\\" + w + \\\"_wrt_pacman\\\"].isnull(), \\\"base\\\" + w\\n        ] = df_total.loc[\\n            ~df_total[\\\"ghost\\\" + w + \\\"_wrt_pacman\\\"].isnull(), \\\"intersect_cnt\\\" + w\\n        ] / df_total.loc[\\n            ~df_total[\\\"ghost\\\" + w + \\\"_wrt_pacman\\\"].isnull(), \\\"ghost\\\" + w + \\\"_wrt_pacman\\\"\\n        ].map(\\n            len\\n        )\\n        df_total = df_total.drop(columns=[\\\"p_choice\\\", \\\"level_1\\\", \\\"intersect_cnt\\\" + w])\\n    return df_total\\n\\n\\ndef toward_ghost_table(df_total, cond=True):\\n    mapping_d = {\\\"1\\\": \\\"red\\\", \\\"2\\\": \\\"yellow\\\"}\\n    rs = pd.DataFrame()\\n    for w in [\\\"1\\\", \\\"2\\\"]:\\n        if \\\"ghost\\\" + w + \\\"_dimi_manh\\\" not in df_total.columns:\\n            df_total[\\\"ghost\\\" + w + \\\"_dimi_manh\\\"] = (\\n                df_total[[\\\"next_pacman_dir_fill\\\", \\\"ghost\\\" + w + \\\"_wrt_pacman\\\"]]\\n                .explode(\\\"next_pacman_dir_fill\\\")\\n                .explode(\\\"ghost\\\" + w + \\\"_wrt_pacman\\\")\\n                .apply(\\n                    lambda x: x[\\\"ghost\\\" + w + \\\"_wrt_pacman\\\"]\\n                    == x[\\\"next_pacman_dir_fill\\\"],\\n                    1,\\n                )\\n                .max(level=0)\\n            )\\n        rs = pd.concat(\\n            [\\n                rs,\\n                df_total[\\n                    (df_total.pacmanPos != df_total.pacmanPos.shift(-1))\\n                    & (df_total[\\\"ifscared\\\" + w] != 3)\\n                    & (df_total[\\\"base\\\" + w] == 0.5)\\n                    & (df_total[\\\"distance\\\" + w] > 2)\\n                    & cond\\n                    #                     & (\\n                    #                         #                                                 df_total.index.isin(list(itertools.chain(*select_status[key])))\\n                    #                         df_total[select_status[key]]\\n                    #                         == 1\\n                    #                     )\\n                ]\\n                .groupby(\\n                    [\\n                        df_total[\\\"ifscared\\\" + w] >= 3,\\n                        df_total[\\\"distance\\\" + w].apply(lambda x: min(x, 25)),\\n                        \\\"pacmanPos\\\",\\n                        \\\"ghost\\\" + w + \\\"Pos\\\",\\n                    ]\\n                )[\\\"ghost\\\" + w + \\\"_dimi_manh\\\"]\\n                .mean()\\n                .reset_index()\\n                .drop(columns=[\\\"pacmanPos\\\", \\\"ghost\\\" + w + \\\"Pos\\\"])\\n                .groupby([\\\"ifscared\\\" + w, \\\"distance\\\" + w])[\\\"ghost\\\" + w + \\\"_dimi_manh\\\"]\\n                .agg([\\\"mean\\\", \\\"std\\\", \\\"count\\\"])\\n                .unstack(\\\"ifscared\\\" + w)\\n                .rename(\\n                    columns={\\n                        False: \\\"ghost(\\\" + mapping_d[w] + \\\") normal\\\",\\n                        True: \\\"ghost(\\\" + mapping_d[w] + \\\") scared\\\",\\n                    }\\n                ),\\n            ],\\n            1,\\n        )\\n\\n    rs = rs.stack().reset_index()\\n    rs = pd.concat(\\n        [\\n            rs,\\n            rs.ifscared1.str.split(\\\" \\\", expand=True).rename(\\n                columns={0: \\\"ghost\\\", 1: \\\"status\\\"}\\n            ),\\n        ],\\n        1,\\n    )\\n    return rs\\n\\n\\ndef extend_cross_fork(df_overlap, save_path):\\n    df_overlap = df_overlap.merge(\\n        LOCS_DF[LOCS_DF.dis == 1].explode(\\\"relative_dir\\\"),\\n        left_on=[\\\"pacmanPos\\\", \\\"pacman_dir_fill\\\"],\\n        right_on=[\\\"pos1\\\", \\\"relative_dir\\\"],\\n        how=\\\"left\\\",\\n    )\\n    df_overlap = df_overlap[\\n        (\\n            (df_overlap.NextNum == 4)\\n            | ((df_overlap.NextNum == 3) & (df_overlap.pos2.isnull()))\\n        )\\n        & (df_overlap.pacman_dir_fill != df_overlap.next_pacman_dir_fill)\\n    ]\\n    #     if two_sides_diff:\\n    df_overlap[\\\"left_turn\\\"] = df_overlap.pacman_dir_fill.replace(left_turn_mapping)\\n    df_overlap[\\\"right_turn\\\"] = df_overlap[\\\"left_turn\\\"].replace(OPPOSITE_DIRS)\\n    for d in [\\\"left\\\", \\\"right\\\"]:\\n        df_temp = pd.concat(\\n            [\\n                df_overlap[[\\\"up\\\", \\\"down\\\", \\\"right\\\", \\\"left\\\"]].stack().reset_index(1),\\n                df_overlap[d + \\\"_turn\\\"],\\n            ],\\n            1,\\n        )\\n\\n        df_overlap = pd.concat(\\n            [\\n                df_overlap.drop(columns=[d + \\\"_turn\\\"]),\\n                df_temp[df_temp.level_1 == df_temp[d + \\\"_turn\\\"]].rename(\\n                    columns={0: d + \\\"_beans\\\"}\\n                ),\\n            ],\\n            1,\\n        )\\n    sns.set_palette([\\\"darkgreen\\\", \\\"khaki\\\"])\\n    df_overlap.assign(\\n        ifturn_left=(df_overlap.left_turn == df_overlap.next_pacman_dir_fill).fillna(\\n            False\\n        )\\n    ).groupby(\\n        [df_overlap.left_beans - df_overlap.right_beans, \\\"NextNum\\\"]\\n    ).ifturn_left.mean().unstack()[\\n        -6:4\\n    ].fillna(\\n        0\\n    ).plot(\\n        marker=\\\"o\\\"\\n    )\\n    plt.legend([\\\"fork\\\", \\\"cross\\\"])\\n    plt.ylabel(\\\"% of turning left\\\")\\n    plt.xlabel(\\\"# of left beans - right beans\\\")\\n    plt.ylim(-0.2, 1.2)\\n    plt.savefig(save_path)\\n\\n\\ndef exclude_2dirs(df_overlap):\\n    max_2max_columns = select_max_2max_dirs(df_overlap)\\n    df_overlap = pd.concat([df_overlap, max_2max_columns], 1)\\n\\n    df_overlap = df_overlap[\\n        df_overlap.assign(\\n            pacman_opp=df_overlap.pacman_dir_fill.replace(OPPOSITE_DIRS)\\n        ).apply(\\n            lambda x: sorted([x.pacman_opp, x.pacman_dir_fill]) != sorted([x[0], x[1]]),\\n            1,\\n        )\\n    ]\\n    return df_overlap\\n\\n\\ndef go_to_most_beans(\\n    df_overlap, cate_df, save_path, only_cross_fork, exclude_2dirs, landscape\\n):\\n    pp = []\\n    for n in [5]:\\n        if only_cross_fork:\\n            \\\"\\\"\\\"\\u8fd9\\u4e2a\\u4ec5\\u4ec5\\u9002\\u5408n=5\\u7684\\u60c5\\u51b5\\\"\\\"\\\"\\n            extend_cross_fork(df_overlap, save_path)\\n            break\\n        if exclude_2dirs:\\n            df_overlap = exclude_2dirs(df_overlap)\\n\\n        \\\"\\\"\\\"1)\\u662f\\u5426\\u9009\\u62e9\\u4e86\\u6700\\u5927\\u7684\\u65b9\\u5411choice_large 2) \\u8fd9\\u4e2a\\u4f4d\\u7f6e\\u662f\\u4e0d\\u662f\\u8f6c\\u5f2f\\u53e3\\\"\\\"\\\"\\n        df_overlap = df_overlap.assign(\\n            choice_large=df_overlap.apply(\\n                lambda x: x.next_pacman_dir_fill == random.choice(x.largest_dir), 1\\n            ),\\n            if_cross=df_overlap.pacmanPos.isin(TURNING_POS),\\n        )\\n\\n        \\\"\\\"\\\"\\u51c6\\u5907\\u753b\\u56fe\\u5143\\u7d20\\\"\\\"\\\"\\n        \\\"\\\"\\\"\\u5982\\u679c\\u9700\\u8981\\u6309\\u7167\\u5730\\u5f62\\u6765\\u5206\\u7684\\u8bdd\\uff0c\\u9700\\u8981\\u628acomment\\u6389\\u7684\\u4e1c\\u897f\\u90fd\\u6062\\u590d\\\"\\\"\\\"\\n        result_df = (\\n            df_overlap[df_overlap[[\\\"down\\\", \\\"up\\\", \\\"left\\\", \\\"right\\\"]].max(1) > 0]\\n            .groupby(\\n                [\\n                    \\\"NextNum\\\",\\n                    \\\"if_cross\\\",\\n                    df_overlap[\\n                        df_overlap[[\\\"down\\\", \\\"up\\\", \\\"left\\\", \\\"right\\\"]].max(1) > 0\\n                    ].local_4dirs_diff.apply(lambda x: min(x, 4)),\\n                ]\\n            )\\n            .choice_large.apply(\\n                lambda x: pd.Series({\\\"mean\\\": x.mean(), \\\"count\\\": len(x), \\\"std\\\": x.std()})\\n            )\\n            .unstack()\\n            .reset_index()\\n        ).merge(cate_df, on=[\\\"if_cross\\\", \\\"NextNum\\\"], how=\\\"left\\\",)\\n        #     result_df = result_df[result_df.category.isin([\\\"fork\\\", \\\"cross\\\"])]\\n        if landscape:\\n            plt.figure(dpi=300)\\n            sns.scatterplot(\\n                data=result_df,\\n                x=\\\"local_4dirs_diff\\\",\\n                y=\\\"mean\\\",\\n                #             size=result_df[\\\"count\\\"],\\n                ax=ax,\\n                hue=\\\"category\\\",\\n                hue_order=[\\\"straight\\\", \\\"L-shape\\\", \\\"fork\\\", \\\"cross\\\"],\\n                sizes=(20, 200),\\n            )\\n            for c in [\\\"straight\\\", \\\"L-shape\\\", \\\"fork\\\", \\\"cross\\\"]:\\n                gpd = result_df[result_df.category == c]\\n                ax.errorbar(\\n                    gpd[\\\"local_4dirs_diff\\\"],\\n                    gpd[\\\"mean\\\"],\\n                    yerr=gpd[\\\"std\\\"] / np.sqrt(gpd[\\\"count\\\"]),\\n                    marker=None,\\n                    capsize=3,\\n                )\\n            ax.legend()\\n            ax.set_xticks([0, 1, 2, 3, 4])\\n            ax.set_xticklabels([0, 1, 2, 3, \\\">=4\\\"])\\n            ax.set_xlabel(\\\"local reward max - 2nd max\\\")\\n            ax.set_ylabel(\\\"% of toward the most valuable direction\\\")\\n            ax.set_title(\\\"errorbar = traditional std\\\")\\n            ax.set_ylim(0, 1)\\n            ax.figure.savefig(save_path)\\n        else:\\n            errorplot = ax.errorbar(\\n                result_df[result_df.category == land][\\\"local_4dirs_diff\\\"],\\n                result_df[result_df.category == land][\\\"mean\\\"],\\n                #         yerr=result_df[\\\"std\\\"] / np.sqrt(result_df[\\\"count\\\"]),\\n                marker=\\\"o\\\",\\n                #         capsize=3,\\n            )\\n            pp.append(errorplot.lines[0])\\n\\n            # use them in the legend\\n            ax.legend(pp, [str(i) for i in [1, 3, 5, 7]], ncol=4, numpoints=1)\\n            ax.set_xticks([0, 1, 2, 3, 4])\\n            ax.set_xticklabels([0, 1, 2, 3, \\\">=4\\\"])\\n            plt.xlabel(\\\"local reward max - 2nd max\\\")\\n            plt.ylabel(\\\"% of toward the most valuable direction\\\")\\n            plt.title(land.capitalize() + \\\" Local Graze\\\")\\n            plt.savefig(save_path)\\n\\n\\ndef add_PEG_dis(df_total):\\n    diss = add_dis(\\n        add_dis(\\n            add_dis(\\n                df_total[\\n                    [\\\"ghost2Pos\\\", \\\"ghost1Pos\\\", \\\"next_eat_energizer\\\", \\\"pacmanPos\\\"]\\n                ].reset_index(),\\n                \\\"pacmanPos\\\",\\n                \\\"next_eat_energizer\\\",\\n                \\\"PE_dis\\\",\\n            ),\\n            \\\"next_eat_energizer\\\",\\n            \\\"ghost1Pos\\\",\\n            \\\"EG1_dis\\\",\\n        ),\\n        \\\"next_eat_energizer\\\",\\n        \\\"ghost2Pos\\\",\\n        \\\"EG2_dis\\\",\\n    )\\n\\n    diss[\\\"EG_dis\\\"] = diss[[\\\"EG1_dis\\\", \\\"EG2_dis\\\"]].min(1)\\n\\n    df_total = pd.concat(\\n        [\\n            df_total,\\n            diss.set_index(\\\"level_0\\\")[[\\\"PE_dis\\\", \\\"EG_dis\\\", \\\"EG1_dis\\\", \\\"EG2_dis\\\"]],\\n        ],\\n        1,\\n    )\\n    return df_total\\n\\n\\ndef count_change_dir(x):\\n    \\\"\\\"\\\"x: [[(1,2),(4,5)]]\\\"\\\"\\\"\\n    df_temp = pd.DataFrame(x).T.reset_index()\\n    move_dir = add_move_dir(df_temp, 0, \\\"move_dir\\\", direction=1).move_dir.explode()\\n    return (move_dir.fillna(method=\\\"bfill\\\") != move_dir.fillna(method=\\\"bfill\\\").shift())[\\n        1:\\n    ].sum()\\n\\n\\ndef generate_cons(df_total):\\n    cons_list_accident = (\\n        df_total[df_total.status == \\\"local\\\"]\\n        .groupby(\\\"file\\\")\\n        .apply(lambda x: x.index.tolist())\\n        .reset_index()[0]\\n    )\\n    cons_list_plan = (\\n        df_total[df_total.status == \\\"planned_hunting\\\"]\\n        .groupby(\\\"file\\\")\\n        .apply(lambda x: x.index.tolist())\\n        .reset_index()[0]\\n    )\\n    return cons_list_accident, cons_list_plan\\n\\n\\ndef add_nearest_rwd_reset(df_total):\\n    \\\"\\\"\\\"\\n    \\u5bf9\\u6bcf\\u4e00\\u6b65\\u6dfb\\u52a0\\u6700\\u8fd1\\u7684\\u70b9(\\u6709\\u53ef\\u80fd\\u662f\\u591a\\u4e2a\\u70b9\\uff0c\\u6240\\u4ee5\\u5bf9\\u4e8e\\u6bcf\\u4e2a\\u70b9return\\u7684\\u662f\\u4e00\\u4e2alist)\\n    \\\"\\\"\\\"\\n    tmp = add_dis(\\n        df_total[[\\\"beans\\\", \\\"file\\\", \\\"index\\\"]]\\n        .assign(reset_pos=[(14, 27)] * df_total.shape[0])\\n        .explode(\\\"beans\\\"),\\n        \\\"reset_pos\\\",\\n        \\\"beans\\\",\\n    )\\n    tmp = (\\n        tmp.merge(\\n            tmp.groupby([\\\"file\\\", \\\"index\\\"]).dis.min().reset_index(),\\n            on=[\\\"dis\\\", \\\"file\\\", \\\"index\\\"],\\n        )\\n        .groupby([\\\"file\\\", \\\"index\\\", \\\"dis\\\"])\\n        .apply(lambda x: list(x.beans))\\n        .reset_index()\\n        .rename(columns={0: \\\"nearresetPos\\\", \\\"dis\\\": \\\"rwd_reset_distance\\\"})\\n    )\\n\\n    return df_total.merge(tmp, on=[\\\"file\\\", \\\"index\\\"], how=\\\"left\\\")\\n\\n\\ndef label_hunts(df_model):\\n    hunt_index1 = (\\n        ((df_model.status_e1 == 0) & (df_model.status_h1 == 1))\\n        .replace({False: np.nan})\\n        .dropna()\\n        .index.tolist()\\n    )\\n\\n    hunt_index2 = (\\n        ((df_model.status_e2 == 0) & (df_model.status_h2 == 1))\\n        .replace({False: np.nan})\\n        .dropna()\\n        .index.tolist()\\n    )\\n    prehunt_index = (\\n        ((df_model.status_h1 == -1) | (df_model.status_h2 == -1))\\n        .replace({False: np.nan})\\n        .dropna()\\n        .index.tolist()\\n    )\\n    df_model.loc[hunt_index1, \\\"label_hunt1\\\"] = 1\\n    df_model.loc[hunt_index2, \\\"label_hunt2\\\"] = 1\\n    df_model.loc[prehunt_index, \\\"label_prehunt\\\"] = 1\\n\\n\\ndef plot_eating(df_pos, idx, reward_sel):\\n    f, ax = plt.subplots(figsize=(10, 10))\\n    sns.heatmap(ARRAY, ax=ax, linewidth=0.5, annot=False, cbar=False, cmap=\\\"bone\\\")\\n    bottom, top = ax.get_ylim()\\n    ax.set_ylim(bottom + 0.5, top - 0.5)\\n    ax.set_title(df_pos.file.values[0])\\n\\n    plt.scatter(\\n        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward <= 2)].X + 0.5,\\n        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward <= 2)].Y + 0.5,\\n        color=\\\"brown\\\",\\n        s=reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward <= 2)].Reward * 70,\\n        marker=get_marker(SYMBOLS[\\\"cookie\\\"]),\\n    )\\n    plt.scatter(\\n        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward > 2)].X + 0.5,\\n        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward > 2)].Y + 0.5,\\n        color=\\\"red\\\",\\n        s=120,\\n        marker=get_marker(SYMBOLS[\\\"apple\\\"]),\\n    )\\n    plt.scatter(\\n        np.array(df_pos.loc[idx, \\\"pacmanPos\\\"])[0] + 0.5,\\n        np.array(df_pos.loc[idx, \\\"pacmanPos\\\"])[1] + 0.5,\\n        marker=get_marker(SYMBOLS[\\\"monkey\\\"]),\\n        s=300,\\n        color=\\\"green\\\",\\n    )  # pacman\\n\\n    #     plt.text(\\n    #         x=40,\\n    #         y=6,\\n    #         s=\\\"global_Q: \\\" + str(df_pos.loc[idx, \\\"global_Q\\\"]),\\n    #         horizontalalignment=\\\"right\\\",\\n    #     )\\n    #     plt.text(\\n    #         x=40,\\n    #         y=7,\\n    #         s=\\\"local_Q: \\\" + str(df_pos.loc[idx, \\\"local_Q\\\"]),\\n    #         horizontalalignment=\\\"right\\\",\\n    #     )\\n    #     plt.text(\\n    #         x=40,\\n    #         y=8,\\n    #         s=\\\"pess_Q: \\\" + str(df_pos.loc[idx, \\\"pessimistic_Q\\\"]),\\n    #         horizontalalignment=\\\"right\\\",\\n    #     )\\n\\n    plt.text(\\n        x=40,\\n        y=9,\\n        #         s=\\\"current index: \\\" + str(idx + df_pos[\\\"index\\\"].values[0]),\\n        s=\\\"current index: \\\" + str(idx),\\n        horizontalalignment=\\\"right\\\",\\n    )\\n    plt.text(\\n        x=40,\\n        y=10,\\n        s=\\\"handcraft_label: \\\" + \\\", \\\".join(np.ravel(df_pos.loc[0, \\\"fitted_label\\\"])),\\n        horizontalalignment=\\\"right\\\",\\n    )\\n    plt.text(\\n        x=40,\\n        y=11,\\n        s=\\\"estimated_label: \\\" + \\\", \\\".join(np.ravel(df_pos.loc[0, \\\"rulebased_label\\\"])),\\n        horizontalalignment=\\\"right\\\",\\n    )\\n    for cnt, i in enumerate(\\n        [\\\"global\\\", \\\"local\\\", \\\"evade(Blinky)\\\", \\\"evade(Clyde)\\\", \\\"approach\\\", \\\"energizer\\\"]\\n    ):\\n        plt.text(\\n            x=40,\\n            y=12 + cnt,\\n            s=i + \\\": \\\" + str(np.round(df_pos.loc[idx, i + \\\"_weight\\\"], 2)),\\n            horizontalalignment=\\\"right\\\",\\n        )\\n\\n    if df_pos.loc[idx, \\\"ifscared1\\\"] < 3:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"ghost\\\"]),\\n            s=300,\\n            color=\\\"red\\\",\\n        )  # normal ghost\\n    elif df_pos.loc[idx, \\\"ifscared1\\\"] >= 4:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"ghost\\\"]),\\n            s=300,\\n            color=\\\"white\\\",\\n            edgecolor=\\\"red\\\",\\n        )  # scared + flashing ghost\\n    else:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"eye\\\"]),\\n            s=30,\\n            color=\\\"white\\\",\\n            edgecolor=\\\"black\\\",  # dead ghost\\n        )\\n    if df_pos.loc[idx, \\\"ifscared2\\\"] < 3:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"ghost\\\"]),\\n            s=300,\\n            color=\\\"orange\\\",\\n        )  # normal ghost\\n    elif df_pos.loc[idx, \\\"ifscared2\\\"] >= 4:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"ghost\\\"]),\\n            s=300,\\n            color=\\\"white\\\",\\n            edgecolor=\\\"orange\\\",\\n        )  # scared + flashing ghost\\n    else:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"eye\\\"]),\\n            s=30,\\n            color=\\\"white\\\",\\n            edgecolor=\\\"black\\\",  # dead ghost\\n        )\\n\\n\\ndef generate_qtable(df_output, filename, window_size=3):\\n    Q_table = pd.DataFrame()\\n    file_data = [j for j in df_output if j[-1] == filename][0]\\n    set_trace()\\n    for start_index, sub in enumerate(file_data[4].round(2)):\\n        df_temp = pd.concat(\\n            [\\n                pd.Series([list(i[0]), list(i[1])], index=[\\\"local_Q\\\", \\\"pessimistic_Q\\\"],)\\n                for i in sub\\n            ],\\n            1,\\n        ).T\\n        df_temp.index = range(start_index, start_index + 2 * window_size + 1)\\n        Q_table = Q_table.append(df_temp)\\n    Q_table = (\\n        Q_table[~Q_table.index.duplicated(keep=\\\"first\\\")][window_size:-window_size]\\n        .reset_index()\\n        .drop(\\\"index\\\", 1)\\n    )\\n    return Q_table\\n\\n\\ndef add_pess(x):\\n    if x.estimated_label == [\\\"pessimistic\\\"]:\\n        return x.estimated_label\\n    if x.estimated_label != [\\\"\\\"]:\\n        if x.pessimistic_weight > 0.5:\\n            return [x.estimated_label[0], \\\"pessimistic\\\"]\\n        else:\\n            return x.estimated_label\";\n",
       "                var nbb_formatted_code = \"def set_landcolor(landscape_colors, landscape=True, land=None):\\n    if landscape:\\n        sns.set_palette(landscape_colors.values())\\n    else:\\n        if land == \\\"straight\\\":\\n            sns.set_palette(plt.cm.Reds(np.linspace(0.3, 1, 4)))\\n        if land == \\\"L-shape\\\":\\n            sns.set_palette(plt.cm.Blues(np.linspace(0.3, 1, 4)))\\n        if land == \\\"fork\\\":\\n            sns.set_palette(plt.cm.Greens(np.linspace(0.3, 1, 4)))\\n        if land == \\\"cross\\\":\\n            sns.set_palette(plt.cm.Wistia(np.linspace(0.3, 1, 4)))\\n\\n\\ndef extend_df_overlap(df_total, condition, data_type=\\\"simulated\\\"):\\n    if data_type != \\\"simulated\\\":\\n        df_overlap = pd.read_pickle(\\n            \\\"../constants/df_overlap_\\\" + \\\"omega\\\" + \\\".pkl\\\"\\n        ).append(pd.read_pickle(\\\"../constants/df_overlap_\\\" + \\\"patamon\\\" + \\\".pkl\\\"))\\n    else:\\n        df_overlap = pd.read_pickle(\\\"../constants/df_overlap_simulated.pkl\\\")\\n    df_filter = df_total.loc[\\n        condition,\\n        [\\\"file\\\", \\\"index\\\", \\\"next_pacman_dir_fill\\\", \\\"pacmanPos\\\", \\\"pacman_dir_fill\\\",],\\n    ]\\n    df_overlap = (\\n        df_overlap.assign(\\n            local_4dirs_diff=largest_2ndlargest_diff(df_overlap),\\n            largest_dir=df_overlap.eq(df_overlap.max(1), axis=0)\\n            .stack()\\n            .replace({False: np.nan})\\n            .dropna()\\n            .reset_index()\\n            .groupby([\\\"file\\\", \\\"index\\\"])\\n            .apply(lambda x: list(x.local_feature_dir)),\\n        )\\n        .reset_index()\\n        .merge(df_filter, on=[\\\"file\\\", \\\"index\\\"], how=\\\"left\\\",)\\n        .merge(MAP_INFO[[\\\"NextNum\\\", \\\"pos\\\"]], left_on=\\\"pacmanPos\\\", right_on=\\\"pos\\\")\\n        .drop(columns=[\\\"pos\\\"])\\n    )\\n    return df_overlap\\n\\n\\ndef intersect_cnt(df, col1, col2):\\n    df[\\\"intersect_cnt\\\"] = df.apply(\\n        lambda x: len(set(x[col1]) & set(x[col2]))\\n        if not isinstance(x[col1], float) and not isinstance(x[col2], float)\\n        else np.nan,\\n        1,\\n    )\\n    return df\\n\\n\\ndef add_possible_dirs(df_total):\\n    for w in [\\\"1\\\", \\\"2\\\"]:\\n        df_total = (\\n            intersect_cnt(\\n                df_total.reset_index()\\n                .merge(\\n                    POSSIBLE_DIRS, left_on=\\\"pacmanPos\\\", right_on=\\\"p_choice\\\", how=\\\"left\\\"\\n                )\\n                .set_index(\\\"level_0\\\"),\\n                \\\"level_1\\\",\\n                \\\"ghost\\\" + w + \\\"_wrt_pacman\\\",\\n            )\\n            .sort_index()\\n            .rename(columns={\\\"intersect_cnt\\\": \\\"intersect_cnt\\\" + w})\\n        )\\n        df_total.loc[\\n            ~df_total[\\\"ghost\\\" + w + \\\"_wrt_pacman\\\"].isnull(), \\\"base\\\" + w\\n        ] = df_total.loc[\\n            ~df_total[\\\"ghost\\\" + w + \\\"_wrt_pacman\\\"].isnull(), \\\"intersect_cnt\\\" + w\\n        ] / df_total.loc[\\n            ~df_total[\\\"ghost\\\" + w + \\\"_wrt_pacman\\\"].isnull(), \\\"ghost\\\" + w + \\\"_wrt_pacman\\\"\\n        ].map(\\n            len\\n        )\\n        df_total = df_total.drop(columns=[\\\"p_choice\\\", \\\"level_1\\\", \\\"intersect_cnt\\\" + w])\\n    return df_total\\n\\n\\ndef toward_ghost_table(df_total, cond=True):\\n    mapping_d = {\\\"1\\\": \\\"red\\\", \\\"2\\\": \\\"yellow\\\"}\\n    rs = pd.DataFrame()\\n    for w in [\\\"1\\\", \\\"2\\\"]:\\n        if \\\"ghost\\\" + w + \\\"_dimi_manh\\\" not in df_total.columns:\\n            df_total[\\\"ghost\\\" + w + \\\"_dimi_manh\\\"] = (\\n                df_total[[\\\"next_pacman_dir_fill\\\", \\\"ghost\\\" + w + \\\"_wrt_pacman\\\"]]\\n                .explode(\\\"next_pacman_dir_fill\\\")\\n                .explode(\\\"ghost\\\" + w + \\\"_wrt_pacman\\\")\\n                .apply(\\n                    lambda x: x[\\\"ghost\\\" + w + \\\"_wrt_pacman\\\"]\\n                    == x[\\\"next_pacman_dir_fill\\\"],\\n                    1,\\n                )\\n                .max(level=0)\\n            )\\n        rs = pd.concat(\\n            [\\n                rs,\\n                df_total[\\n                    (df_total.pacmanPos != df_total.pacmanPos.shift(-1))\\n                    & (df_total[\\\"ifscared\\\" + w] != 3)\\n                    & (df_total[\\\"base\\\" + w] == 0.5)\\n                    & (df_total[\\\"distance\\\" + w] > 2)\\n                    & cond\\n                    #                     & (\\n                    #                         #                                                 df_total.index.isin(list(itertools.chain(*select_status[key])))\\n                    #                         df_total[select_status[key]]\\n                    #                         == 1\\n                    #                     )\\n                ]\\n                .groupby(\\n                    [\\n                        df_total[\\\"ifscared\\\" + w] >= 3,\\n                        df_total[\\\"distance\\\" + w].apply(lambda x: min(x, 25)),\\n                        \\\"pacmanPos\\\",\\n                        \\\"ghost\\\" + w + \\\"Pos\\\",\\n                    ]\\n                )[\\\"ghost\\\" + w + \\\"_dimi_manh\\\"]\\n                .mean()\\n                .reset_index()\\n                .drop(columns=[\\\"pacmanPos\\\", \\\"ghost\\\" + w + \\\"Pos\\\"])\\n                .groupby([\\\"ifscared\\\" + w, \\\"distance\\\" + w])[\\\"ghost\\\" + w + \\\"_dimi_manh\\\"]\\n                .agg([\\\"mean\\\", \\\"std\\\", \\\"count\\\"])\\n                .unstack(\\\"ifscared\\\" + w)\\n                .rename(\\n                    columns={\\n                        False: \\\"ghost(\\\" + mapping_d[w] + \\\") normal\\\",\\n                        True: \\\"ghost(\\\" + mapping_d[w] + \\\") scared\\\",\\n                    }\\n                ),\\n            ],\\n            1,\\n        )\\n\\n    rs = rs.stack().reset_index()\\n    rs = pd.concat(\\n        [\\n            rs,\\n            rs.ifscared1.str.split(\\\" \\\", expand=True).rename(\\n                columns={0: \\\"ghost\\\", 1: \\\"status\\\"}\\n            ),\\n        ],\\n        1,\\n    )\\n    return rs\\n\\n\\ndef extend_cross_fork(df_overlap, save_path):\\n    df_overlap = df_overlap.merge(\\n        LOCS_DF[LOCS_DF.dis == 1].explode(\\\"relative_dir\\\"),\\n        left_on=[\\\"pacmanPos\\\", \\\"pacman_dir_fill\\\"],\\n        right_on=[\\\"pos1\\\", \\\"relative_dir\\\"],\\n        how=\\\"left\\\",\\n    )\\n    df_overlap = df_overlap[\\n        (\\n            (df_overlap.NextNum == 4)\\n            | ((df_overlap.NextNum == 3) & (df_overlap.pos2.isnull()))\\n        )\\n        & (df_overlap.pacman_dir_fill != df_overlap.next_pacman_dir_fill)\\n    ]\\n    #     if two_sides_diff:\\n    df_overlap[\\\"left_turn\\\"] = df_overlap.pacman_dir_fill.replace(left_turn_mapping)\\n    df_overlap[\\\"right_turn\\\"] = df_overlap[\\\"left_turn\\\"].replace(OPPOSITE_DIRS)\\n    for d in [\\\"left\\\", \\\"right\\\"]:\\n        df_temp = pd.concat(\\n            [\\n                df_overlap[[\\\"up\\\", \\\"down\\\", \\\"right\\\", \\\"left\\\"]].stack().reset_index(1),\\n                df_overlap[d + \\\"_turn\\\"],\\n            ],\\n            1,\\n        )\\n\\n        df_overlap = pd.concat(\\n            [\\n                df_overlap.drop(columns=[d + \\\"_turn\\\"]),\\n                df_temp[df_temp.level_1 == df_temp[d + \\\"_turn\\\"]].rename(\\n                    columns={0: d + \\\"_beans\\\"}\\n                ),\\n            ],\\n            1,\\n        )\\n    sns.set_palette([\\\"darkgreen\\\", \\\"khaki\\\"])\\n    df_overlap.assign(\\n        ifturn_left=(df_overlap.left_turn == df_overlap.next_pacman_dir_fill).fillna(\\n            False\\n        )\\n    ).groupby(\\n        [df_overlap.left_beans - df_overlap.right_beans, \\\"NextNum\\\"]\\n    ).ifturn_left.mean().unstack()[\\n        -6:4\\n    ].fillna(\\n        0\\n    ).plot(\\n        marker=\\\"o\\\"\\n    )\\n    plt.legend([\\\"fork\\\", \\\"cross\\\"])\\n    plt.ylabel(\\\"% of turning left\\\")\\n    plt.xlabel(\\\"# of left beans - right beans\\\")\\n    plt.ylim(-0.2, 1.2)\\n    plt.savefig(save_path)\\n\\n\\ndef exclude_2dirs(df_overlap):\\n    max_2max_columns = select_max_2max_dirs(df_overlap)\\n    df_overlap = pd.concat([df_overlap, max_2max_columns], 1)\\n\\n    df_overlap = df_overlap[\\n        df_overlap.assign(\\n            pacman_opp=df_overlap.pacman_dir_fill.replace(OPPOSITE_DIRS)\\n        ).apply(\\n            lambda x: sorted([x.pacman_opp, x.pacman_dir_fill]) != sorted([x[0], x[1]]),\\n            1,\\n        )\\n    ]\\n    return df_overlap\\n\\n\\ndef go_to_most_beans(\\n    df_overlap, cate_df, save_path, only_cross_fork, exclude_2dirs, landscape\\n):\\n    pp = []\\n    for n in [5]:\\n        if only_cross_fork:\\n            \\\"\\\"\\\"\\u8fd9\\u4e2a\\u4ec5\\u4ec5\\u9002\\u5408n=5\\u7684\\u60c5\\u51b5\\\"\\\"\\\"\\n            extend_cross_fork(df_overlap, save_path)\\n            break\\n        if exclude_2dirs:\\n            df_overlap = exclude_2dirs(df_overlap)\\n\\n        \\\"\\\"\\\"1)\\u662f\\u5426\\u9009\\u62e9\\u4e86\\u6700\\u5927\\u7684\\u65b9\\u5411choice_large 2) \\u8fd9\\u4e2a\\u4f4d\\u7f6e\\u662f\\u4e0d\\u662f\\u8f6c\\u5f2f\\u53e3\\\"\\\"\\\"\\n        df_overlap = df_overlap.assign(\\n            choice_large=df_overlap.apply(\\n                lambda x: x.next_pacman_dir_fill == random.choice(x.largest_dir), 1\\n            ),\\n            if_cross=df_overlap.pacmanPos.isin(TURNING_POS),\\n        )\\n\\n        \\\"\\\"\\\"\\u51c6\\u5907\\u753b\\u56fe\\u5143\\u7d20\\\"\\\"\\\"\\n        \\\"\\\"\\\"\\u5982\\u679c\\u9700\\u8981\\u6309\\u7167\\u5730\\u5f62\\u6765\\u5206\\u7684\\u8bdd\\uff0c\\u9700\\u8981\\u628acomment\\u6389\\u7684\\u4e1c\\u897f\\u90fd\\u6062\\u590d\\\"\\\"\\\"\\n        result_df = (\\n            df_overlap[df_overlap[[\\\"down\\\", \\\"up\\\", \\\"left\\\", \\\"right\\\"]].max(1) > 0]\\n            .groupby(\\n                [\\n                    \\\"NextNum\\\",\\n                    \\\"if_cross\\\",\\n                    df_overlap[\\n                        df_overlap[[\\\"down\\\", \\\"up\\\", \\\"left\\\", \\\"right\\\"]].max(1) > 0\\n                    ].local_4dirs_diff.apply(lambda x: min(x, 4)),\\n                ]\\n            )\\n            .choice_large.apply(\\n                lambda x: pd.Series({\\\"mean\\\": x.mean(), \\\"count\\\": len(x), \\\"std\\\": x.std()})\\n            )\\n            .unstack()\\n            .reset_index()\\n        ).merge(cate_df, on=[\\\"if_cross\\\", \\\"NextNum\\\"], how=\\\"left\\\",)\\n        #     result_df = result_df[result_df.category.isin([\\\"fork\\\", \\\"cross\\\"])]\\n        if landscape:\\n            plt.figure(dpi=300)\\n            sns.scatterplot(\\n                data=result_df,\\n                x=\\\"local_4dirs_diff\\\",\\n                y=\\\"mean\\\",\\n                #             size=result_df[\\\"count\\\"],\\n                ax=ax,\\n                hue=\\\"category\\\",\\n                hue_order=[\\\"straight\\\", \\\"L-shape\\\", \\\"fork\\\", \\\"cross\\\"],\\n                sizes=(20, 200),\\n            )\\n            for c in [\\\"straight\\\", \\\"L-shape\\\", \\\"fork\\\", \\\"cross\\\"]:\\n                gpd = result_df[result_df.category == c]\\n                ax.errorbar(\\n                    gpd[\\\"local_4dirs_diff\\\"],\\n                    gpd[\\\"mean\\\"],\\n                    yerr=gpd[\\\"std\\\"] / np.sqrt(gpd[\\\"count\\\"]),\\n                    marker=None,\\n                    capsize=3,\\n                )\\n            ax.legend()\\n            ax.set_xticks([0, 1, 2, 3, 4])\\n            ax.set_xticklabels([0, 1, 2, 3, \\\">=4\\\"])\\n            ax.set_xlabel(\\\"local reward max - 2nd max\\\")\\n            ax.set_ylabel(\\\"% of toward the most valuable direction\\\")\\n            ax.set_title(\\\"errorbar = traditional std\\\")\\n            ax.set_ylim(0, 1)\\n            ax.figure.savefig(save_path)\\n        else:\\n            errorplot = ax.errorbar(\\n                result_df[result_df.category == land][\\\"local_4dirs_diff\\\"],\\n                result_df[result_df.category == land][\\\"mean\\\"],\\n                #         yerr=result_df[\\\"std\\\"] / np.sqrt(result_df[\\\"count\\\"]),\\n                marker=\\\"o\\\",\\n                #         capsize=3,\\n            )\\n            pp.append(errorplot.lines[0])\\n\\n            # use them in the legend\\n            ax.legend(pp, [str(i) for i in [1, 3, 5, 7]], ncol=4, numpoints=1)\\n            ax.set_xticks([0, 1, 2, 3, 4])\\n            ax.set_xticklabels([0, 1, 2, 3, \\\">=4\\\"])\\n            plt.xlabel(\\\"local reward max - 2nd max\\\")\\n            plt.ylabel(\\\"% of toward the most valuable direction\\\")\\n            plt.title(land.capitalize() + \\\" Local Graze\\\")\\n            plt.savefig(save_path)\\n\\n\\ndef add_PEG_dis(df_total):\\n    diss = add_dis(\\n        add_dis(\\n            add_dis(\\n                df_total[\\n                    [\\\"ghost2Pos\\\", \\\"ghost1Pos\\\", \\\"next_eat_energizer\\\", \\\"pacmanPos\\\"]\\n                ].reset_index(),\\n                \\\"pacmanPos\\\",\\n                \\\"next_eat_energizer\\\",\\n                \\\"PE_dis\\\",\\n            ),\\n            \\\"next_eat_energizer\\\",\\n            \\\"ghost1Pos\\\",\\n            \\\"EG1_dis\\\",\\n        ),\\n        \\\"next_eat_energizer\\\",\\n        \\\"ghost2Pos\\\",\\n        \\\"EG2_dis\\\",\\n    )\\n\\n    diss[\\\"EG_dis\\\"] = diss[[\\\"EG1_dis\\\", \\\"EG2_dis\\\"]].min(1)\\n\\n    df_total = pd.concat(\\n        [\\n            df_total,\\n            diss.set_index(\\\"level_0\\\")[[\\\"PE_dis\\\", \\\"EG_dis\\\", \\\"EG1_dis\\\", \\\"EG2_dis\\\"]],\\n        ],\\n        1,\\n    )\\n    return df_total\\n\\n\\ndef count_change_dir(x):\\n    \\\"\\\"\\\"x: [[(1,2),(4,5)]]\\\"\\\"\\\"\\n    df_temp = pd.DataFrame(x).T.reset_index()\\n    move_dir = add_move_dir(df_temp, 0, \\\"move_dir\\\", direction=1).move_dir.explode()\\n    return (move_dir.fillna(method=\\\"bfill\\\") != move_dir.fillna(method=\\\"bfill\\\").shift())[\\n        1:\\n    ].sum()\\n\\n\\ndef generate_cons(df_total):\\n    cons_list_accident = (\\n        df_total[df_total.status == \\\"local\\\"]\\n        .groupby(\\\"file\\\")\\n        .apply(lambda x: x.index.tolist())\\n        .reset_index()[0]\\n    )\\n    cons_list_plan = (\\n        df_total[df_total.status == \\\"planned_hunting\\\"]\\n        .groupby(\\\"file\\\")\\n        .apply(lambda x: x.index.tolist())\\n        .reset_index()[0]\\n    )\\n    return cons_list_accident, cons_list_plan\\n\\n\\ndef add_nearest_rwd_reset(df_total):\\n    \\\"\\\"\\\"\\n    \\u5bf9\\u6bcf\\u4e00\\u6b65\\u6dfb\\u52a0\\u6700\\u8fd1\\u7684\\u70b9(\\u6709\\u53ef\\u80fd\\u662f\\u591a\\u4e2a\\u70b9\\uff0c\\u6240\\u4ee5\\u5bf9\\u4e8e\\u6bcf\\u4e2a\\u70b9return\\u7684\\u662f\\u4e00\\u4e2alist)\\n    \\\"\\\"\\\"\\n    tmp = add_dis(\\n        df_total[[\\\"beans\\\", \\\"file\\\", \\\"index\\\"]]\\n        .assign(reset_pos=[(14, 27)] * df_total.shape[0])\\n        .explode(\\\"beans\\\"),\\n        \\\"reset_pos\\\",\\n        \\\"beans\\\",\\n    )\\n    tmp = (\\n        tmp.merge(\\n            tmp.groupby([\\\"file\\\", \\\"index\\\"]).dis.min().reset_index(),\\n            on=[\\\"dis\\\", \\\"file\\\", \\\"index\\\"],\\n        )\\n        .groupby([\\\"file\\\", \\\"index\\\", \\\"dis\\\"])\\n        .apply(lambda x: list(x.beans))\\n        .reset_index()\\n        .rename(columns={0: \\\"nearresetPos\\\", \\\"dis\\\": \\\"rwd_reset_distance\\\"})\\n    )\\n\\n    return df_total.merge(tmp, on=[\\\"file\\\", \\\"index\\\"], how=\\\"left\\\")\\n\\n\\ndef label_hunts(df_model):\\n    hunt_index1 = (\\n        ((df_model.status_e1 == 0) & (df_model.status_h1 == 1))\\n        .replace({False: np.nan})\\n        .dropna()\\n        .index.tolist()\\n    )\\n\\n    hunt_index2 = (\\n        ((df_model.status_e2 == 0) & (df_model.status_h2 == 1))\\n        .replace({False: np.nan})\\n        .dropna()\\n        .index.tolist()\\n    )\\n    prehunt_index = (\\n        ((df_model.status_h1 == -1) | (df_model.status_h2 == -1))\\n        .replace({False: np.nan})\\n        .dropna()\\n        .index.tolist()\\n    )\\n    df_model.loc[hunt_index1, \\\"label_hunt1\\\"] = 1\\n    df_model.loc[hunt_index2, \\\"label_hunt2\\\"] = 1\\n    df_model.loc[prehunt_index, \\\"label_prehunt\\\"] = 1\\n\\n\\ndef plot_eating(df_pos, idx, reward_sel):\\n    f, ax = plt.subplots(figsize=(10, 10))\\n    sns.heatmap(ARRAY, ax=ax, linewidth=0.5, annot=False, cbar=False, cmap=\\\"bone\\\")\\n    bottom, top = ax.get_ylim()\\n    ax.set_ylim(bottom + 0.5, top - 0.5)\\n    ax.set_title(df_pos.file.values[0])\\n\\n    plt.scatter(\\n        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward <= 2)].X + 0.5,\\n        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward <= 2)].Y + 0.5,\\n        color=\\\"brown\\\",\\n        s=reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward <= 2)].Reward * 70,\\n        marker=get_marker(SYMBOLS[\\\"cookie\\\"]),\\n    )\\n    plt.scatter(\\n        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward > 2)].X + 0.5,\\n        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward > 2)].Y + 0.5,\\n        color=\\\"red\\\",\\n        s=120,\\n        marker=get_marker(SYMBOLS[\\\"apple\\\"]),\\n    )\\n    plt.scatter(\\n        np.array(df_pos.loc[idx, \\\"pacmanPos\\\"])[0] + 0.5,\\n        np.array(df_pos.loc[idx, \\\"pacmanPos\\\"])[1] + 0.5,\\n        marker=get_marker(SYMBOLS[\\\"monkey\\\"]),\\n        s=300,\\n        color=\\\"green\\\",\\n    )  # pacman\\n\\n    #     plt.text(\\n    #         x=40,\\n    #         y=6,\\n    #         s=\\\"global_Q: \\\" + str(df_pos.loc[idx, \\\"global_Q\\\"]),\\n    #         horizontalalignment=\\\"right\\\",\\n    #     )\\n    #     plt.text(\\n    #         x=40,\\n    #         y=7,\\n    #         s=\\\"local_Q: \\\" + str(df_pos.loc[idx, \\\"local_Q\\\"]),\\n    #         horizontalalignment=\\\"right\\\",\\n    #     )\\n    #     plt.text(\\n    #         x=40,\\n    #         y=8,\\n    #         s=\\\"pess_Q: \\\" + str(df_pos.loc[idx, \\\"pessimistic_Q\\\"]),\\n    #         horizontalalignment=\\\"right\\\",\\n    #     )\\n\\n    plt.text(\\n        x=40,\\n        y=9,\\n        #         s=\\\"current index: \\\" + str(idx + df_pos[\\\"index\\\"].values[0]),\\n        s=\\\"current index: \\\" + str(idx),\\n        horizontalalignment=\\\"right\\\",\\n    )\\n    plt.text(\\n        x=40,\\n        y=10,\\n        s=\\\"handcraft_label: \\\" + \\\", \\\".join(np.ravel(df_pos.loc[0, \\\"fitted_label\\\"])),\\n        horizontalalignment=\\\"right\\\",\\n    )\\n    plt.text(\\n        x=40,\\n        y=11,\\n        s=\\\"estimated_label: \\\" + \\\", \\\".join(np.ravel(df_pos.loc[0, \\\"rulebased_label\\\"])),\\n        horizontalalignment=\\\"right\\\",\\n    )\\n    for cnt, i in enumerate(\\n        [\\\"global\\\", \\\"local\\\", \\\"evade(Blinky)\\\", \\\"evade(Clyde)\\\", \\\"approach\\\", \\\"energizer\\\"]\\n    ):\\n        plt.text(\\n            x=40,\\n            y=12 + cnt,\\n            s=i + \\\": \\\" + str(np.round(df_pos.loc[idx, i + \\\"_weight\\\"], 2)),\\n            horizontalalignment=\\\"right\\\",\\n        )\\n\\n    if df_pos.loc[idx, \\\"ifscared1\\\"] < 3:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"ghost\\\"]),\\n            s=300,\\n            color=\\\"red\\\",\\n        )  # normal ghost\\n    elif df_pos.loc[idx, \\\"ifscared1\\\"] >= 4:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"ghost\\\"]),\\n            s=300,\\n            color=\\\"white\\\",\\n            edgecolor=\\\"red\\\",\\n        )  # scared + flashing ghost\\n    else:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost1Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"eye\\\"]),\\n            s=30,\\n            color=\\\"white\\\",\\n            edgecolor=\\\"black\\\",  # dead ghost\\n        )\\n    if df_pos.loc[idx, \\\"ifscared2\\\"] < 3:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"ghost\\\"]),\\n            s=300,\\n            color=\\\"orange\\\",\\n        )  # normal ghost\\n    elif df_pos.loc[idx, \\\"ifscared2\\\"] >= 4:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"ghost\\\"]),\\n            s=300,\\n            color=\\\"white\\\",\\n            edgecolor=\\\"orange\\\",\\n        )  # scared + flashing ghost\\n    else:\\n        plt.scatter(\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[0] + 0.5,\\n            np.array(df_pos.loc[idx, \\\"ghost2Pos\\\"])[1] + 0.5,\\n            marker=get_marker(SYMBOLS[\\\"eye\\\"]),\\n            s=30,\\n            color=\\\"white\\\",\\n            edgecolor=\\\"black\\\",  # dead ghost\\n        )\\n\\n\\ndef generate_qtable(df_output, filename, window_size=3):\\n    Q_table = pd.DataFrame()\\n    file_data = [j for j in df_output if j[-1] == filename][0]\\n    set_trace()\\n    for start_index, sub in enumerate(file_data[4].round(2)):\\n        df_temp = pd.concat(\\n            [\\n                pd.Series([list(i[0]), list(i[1])], index=[\\\"local_Q\\\", \\\"pessimistic_Q\\\"],)\\n                for i in sub\\n            ],\\n            1,\\n        ).T\\n        df_temp.index = range(start_index, start_index + 2 * window_size + 1)\\n        Q_table = Q_table.append(df_temp)\\n    Q_table = (\\n        Q_table[~Q_table.index.duplicated(keep=\\\"first\\\")][window_size:-window_size]\\n        .reset_index()\\n        .drop(\\\"index\\\", 1)\\n    )\\n    return Q_table\\n\\n\\ndef add_pess(x):\\n    if x.estimated_label == [\\\"pessimistic\\\"]:\\n        return x.estimated_label\\n    if x.estimated_label != [\\\"\\\"]:\\n        if x.pessimistic_weight > 0.5:\\n            return [x.estimated_label[0], \\\"pessimistic\\\"]\\n        else:\\n            return x.estimated_label\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_landcolor(landscape_colors, landscape=True, land=None):\n",
    "    if landscape:\n",
    "        sns.set_palette(landscape_colors.values())\n",
    "    else:\n",
    "        if land == \"straight\":\n",
    "            sns.set_palette(plt.cm.Reds(np.linspace(0.3, 1, 4)))\n",
    "        if land == \"L-shape\":\n",
    "            sns.set_palette(plt.cm.Blues(np.linspace(0.3, 1, 4)))\n",
    "        if land == \"fork\":\n",
    "            sns.set_palette(plt.cm.Greens(np.linspace(0.3, 1, 4)))\n",
    "        if land == \"cross\":\n",
    "            sns.set_palette(plt.cm.Wistia(np.linspace(0.3, 1, 4)))\n",
    "\n",
    "\n",
    "def extend_df_overlap(df_total, condition, data_type=\"simulated\"):\n",
    "    if data_type != \"simulated\":\n",
    "        df_overlap = pd.read_pickle(\n",
    "            \"../constants/df_overlap_\" + \"omega\" + \".pkl\"\n",
    "        ).append(pd.read_pickle(\"../constants/df_overlap_\" + \"patamon\" + \".pkl\"))\n",
    "    else:\n",
    "        df_overlap = pd.read_pickle(\"../constants/df_overlap_simulated.pkl\")\n",
    "    df_filter = df_total.loc[\n",
    "        condition,\n",
    "        [\"file\", \"index\", \"next_pacman_dir_fill\", \"pacmanPos\", \"pacman_dir_fill\",],\n",
    "    ]\n",
    "    df_overlap = (\n",
    "        df_overlap.assign(\n",
    "            local_4dirs_diff=largest_2ndlargest_diff(df_overlap),\n",
    "            largest_dir=df_overlap.eq(df_overlap.max(1), axis=0)\n",
    "            .stack()\n",
    "            .replace({False: np.nan})\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .groupby([\"file\", \"index\"])\n",
    "            .apply(lambda x: list(x.local_feature_dir)),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .merge(df_filter, on=[\"file\", \"index\"], how=\"left\",)\n",
    "        .merge(MAP_INFO[[\"NextNum\", \"pos\"]], left_on=\"pacmanPos\", right_on=\"pos\")\n",
    "        .drop(columns=[\"pos\"])\n",
    "    )\n",
    "    return df_overlap\n",
    "\n",
    "\n",
    "def intersect_cnt(df, col1, col2):\n",
    "    df[\"intersect_cnt\"] = df.apply(\n",
    "        lambda x: len(set(x[col1]) & set(x[col2]))\n",
    "        if not isinstance(x[col1], float) and not isinstance(x[col2], float)\n",
    "        else np.nan,\n",
    "        1,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_possible_dirs(df_total):\n",
    "    for w in [\"1\", \"2\"]:\n",
    "        df_total = (\n",
    "            intersect_cnt(\n",
    "                df_total.reset_index()\n",
    "                .merge(\n",
    "                    POSSIBLE_DIRS, left_on=\"pacmanPos\", right_on=\"p_choice\", how=\"left\"\n",
    "                )\n",
    "                .set_index(\"level_0\"),\n",
    "                \"level_1\",\n",
    "                \"ghost\" + w + \"_wrt_pacman\",\n",
    "            )\n",
    "            .sort_index()\n",
    "            .rename(columns={\"intersect_cnt\": \"intersect_cnt\" + w})\n",
    "        )\n",
    "        df_total.loc[\n",
    "            ~df_total[\"ghost\" + w + \"_wrt_pacman\"].isnull(), \"base\" + w\n",
    "        ] = df_total.loc[\n",
    "            ~df_total[\"ghost\" + w + \"_wrt_pacman\"].isnull(), \"intersect_cnt\" + w\n",
    "        ] / df_total.loc[\n",
    "            ~df_total[\"ghost\" + w + \"_wrt_pacman\"].isnull(), \"ghost\" + w + \"_wrt_pacman\"\n",
    "        ].map(\n",
    "            len\n",
    "        )\n",
    "        df_total = df_total.drop(columns=[\"p_choice\", \"level_1\", \"intersect_cnt\" + w])\n",
    "    return df_total\n",
    "\n",
    "\n",
    "def toward_ghost_table(df_total, cond=True):\n",
    "    mapping_d = {\"1\": \"red\", \"2\": \"yellow\"}\n",
    "    rs = pd.DataFrame()\n",
    "    for w in [\"1\", \"2\"]:\n",
    "        if \"ghost\" + w + \"_dimi_manh\" not in df_total.columns:\n",
    "            df_total[\"ghost\" + w + \"_dimi_manh\"] = (\n",
    "                df_total[[\"next_pacman_dir_fill\", \"ghost\" + w + \"_wrt_pacman\"]]\n",
    "                .explode(\"next_pacman_dir_fill\")\n",
    "                .explode(\"ghost\" + w + \"_wrt_pacman\")\n",
    "                .apply(\n",
    "                    lambda x: x[\"ghost\" + w + \"_wrt_pacman\"]\n",
    "                    == x[\"next_pacman_dir_fill\"],\n",
    "                    1,\n",
    "                )\n",
    "                .max(level=0)\n",
    "            )\n",
    "        rs = pd.concat(\n",
    "            [\n",
    "                rs,\n",
    "                df_total[\n",
    "                    (df_total.pacmanPos != df_total.pacmanPos.shift(-1))\n",
    "                    & (df_total[\"ifscared\" + w] != 3)\n",
    "                    & (df_total[\"base\" + w] == 0.5)\n",
    "                    & (df_total[\"distance\" + w] > 2)\n",
    "                    & cond\n",
    "                    #                     & (\n",
    "                    #                         #                                                 df_total.index.isin(list(itertools.chain(*select_status[key])))\n",
    "                    #                         df_total[select_status[key]]\n",
    "                    #                         == 1\n",
    "                    #                     )\n",
    "                ]\n",
    "                .groupby(\n",
    "                    [\n",
    "                        df_total[\"ifscared\" + w] >= 3,\n",
    "                        df_total[\"distance\" + w].apply(lambda x: min(x, 25)),\n",
    "                        \"pacmanPos\",\n",
    "                        \"ghost\" + w + \"Pos\",\n",
    "                    ]\n",
    "                )[\"ghost\" + w + \"_dimi_manh\"]\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "                .drop(columns=[\"pacmanPos\", \"ghost\" + w + \"Pos\"])\n",
    "                .groupby([\"ifscared\" + w, \"distance\" + w])[\"ghost\" + w + \"_dimi_manh\"]\n",
    "                .agg([\"mean\", \"std\", \"count\"])\n",
    "                .unstack(\"ifscared\" + w)\n",
    "                .rename(\n",
    "                    columns={\n",
    "                        False: \"ghost(\" + mapping_d[w] + \") normal\",\n",
    "                        True: \"ghost(\" + mapping_d[w] + \") scared\",\n",
    "                    }\n",
    "                ),\n",
    "            ],\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    rs = rs.stack().reset_index()\n",
    "    rs = pd.concat(\n",
    "        [\n",
    "            rs,\n",
    "            rs.ifscared1.str.split(\" \", expand=True).rename(\n",
    "                columns={0: \"ghost\", 1: \"status\"}\n",
    "            ),\n",
    "        ],\n",
    "        1,\n",
    "    )\n",
    "    return rs\n",
    "\n",
    "\n",
    "def extend_cross_fork(df_overlap, save_path):\n",
    "    df_overlap = df_overlap.merge(\n",
    "        LOCS_DF[LOCS_DF.dis == 1].explode(\"relative_dir\"),\n",
    "        left_on=[\"pacmanPos\", \"pacman_dir_fill\"],\n",
    "        right_on=[\"pos1\", \"relative_dir\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df_overlap = df_overlap[\n",
    "        (\n",
    "            (df_overlap.NextNum == 4)\n",
    "            | ((df_overlap.NextNum == 3) & (df_overlap.pos2.isnull()))\n",
    "        )\n",
    "        & (df_overlap.pacman_dir_fill != df_overlap.next_pacman_dir_fill)\n",
    "    ]\n",
    "    #     if two_sides_diff:\n",
    "    df_overlap[\"left_turn\"] = df_overlap.pacman_dir_fill.replace(left_turn_mapping)\n",
    "    df_overlap[\"right_turn\"] = df_overlap[\"left_turn\"].replace(OPPOSITE_DIRS)\n",
    "    for d in [\"left\", \"right\"]:\n",
    "        df_temp = pd.concat(\n",
    "            [\n",
    "                df_overlap[[\"up\", \"down\", \"right\", \"left\"]].stack().reset_index(1),\n",
    "                df_overlap[d + \"_turn\"],\n",
    "            ],\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        df_overlap = pd.concat(\n",
    "            [\n",
    "                df_overlap.drop(columns=[d + \"_turn\"]),\n",
    "                df_temp[df_temp.level_1 == df_temp[d + \"_turn\"]].rename(\n",
    "                    columns={0: d + \"_beans\"}\n",
    "                ),\n",
    "            ],\n",
    "            1,\n",
    "        )\n",
    "    sns.set_palette([\"darkgreen\", \"khaki\"])\n",
    "    df_overlap.assign(\n",
    "        ifturn_left=(df_overlap.left_turn == df_overlap.next_pacman_dir_fill).fillna(\n",
    "            False\n",
    "        )\n",
    "    ).groupby(\n",
    "        [df_overlap.left_beans - df_overlap.right_beans, \"NextNum\"]\n",
    "    ).ifturn_left.mean().unstack()[\n",
    "        -6:4\n",
    "    ].fillna(\n",
    "        0\n",
    "    ).plot(\n",
    "        marker=\"o\"\n",
    "    )\n",
    "    plt.legend([\"fork\", \"cross\"])\n",
    "    plt.ylabel(\"% of turning left\")\n",
    "    plt.xlabel(\"# of left beans - right beans\")\n",
    "    plt.ylim(-0.2, 1.2)\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "\n",
    "def exclude_2dirs(df_overlap):\n",
    "    max_2max_columns = select_max_2max_dirs(df_overlap)\n",
    "    df_overlap = pd.concat([df_overlap, max_2max_columns], 1)\n",
    "\n",
    "    df_overlap = df_overlap[\n",
    "        df_overlap.assign(\n",
    "            pacman_opp=df_overlap.pacman_dir_fill.replace(OPPOSITE_DIRS)\n",
    "        ).apply(\n",
    "            lambda x: sorted([x.pacman_opp, x.pacman_dir_fill]) != sorted([x[0], x[1]]),\n",
    "            1,\n",
    "        )\n",
    "    ]\n",
    "    return df_overlap\n",
    "\n",
    "\n",
    "def go_to_most_beans(\n",
    "    df_overlap, cate_df, save_path, only_cross_fork, exclude_2dirs, landscape\n",
    "):\n",
    "    pp = []\n",
    "    for n in [5]:\n",
    "        if only_cross_fork:\n",
    "            \"\"\"这个仅仅适合n=5的情况\"\"\"\n",
    "            extend_cross_fork(df_overlap, save_path)\n",
    "            break\n",
    "        if exclude_2dirs:\n",
    "            df_overlap = exclude_2dirs(df_overlap)\n",
    "\n",
    "        \"\"\"1)是否选择了最大的方向choice_large 2) 这个位置是不是转弯口\"\"\"\n",
    "        df_overlap = df_overlap.assign(\n",
    "            choice_large=df_overlap.apply(\n",
    "                lambda x: x.next_pacman_dir_fill == random.choice(x.largest_dir), 1\n",
    "            ),\n",
    "            if_cross=df_overlap.pacmanPos.isin(TURNING_POS),\n",
    "        )\n",
    "\n",
    "        \"\"\"准备画图元素\"\"\"\n",
    "        \"\"\"如果需要按照地形来分的话，需要把comment掉的东西都恢复\"\"\"\n",
    "        result_df = (\n",
    "            df_overlap[df_overlap[[\"down\", \"up\", \"left\", \"right\"]].max(1) > 0]\n",
    "            .groupby(\n",
    "                [\n",
    "                    \"NextNum\",\n",
    "                    \"if_cross\",\n",
    "                    df_overlap[\n",
    "                        df_overlap[[\"down\", \"up\", \"left\", \"right\"]].max(1) > 0\n",
    "                    ].local_4dirs_diff.apply(lambda x: min(x, 4)),\n",
    "                ]\n",
    "            )\n",
    "            .choice_large.apply(\n",
    "                lambda x: pd.Series({\"mean\": x.mean(), \"count\": len(x), \"std\": x.std()})\n",
    "            )\n",
    "            .unstack()\n",
    "            .reset_index()\n",
    "        ).merge(cate_df, on=[\"if_cross\", \"NextNum\"], how=\"left\",)\n",
    "        #     result_df = result_df[result_df.category.isin([\"fork\", \"cross\"])]\n",
    "        if landscape:\n",
    "            plt.figure(dpi=300)\n",
    "            sns.scatterplot(\n",
    "                data=result_df,\n",
    "                x=\"local_4dirs_diff\",\n",
    "                y=\"mean\",\n",
    "                #             size=result_df[\"count\"],\n",
    "                ax=ax,\n",
    "                hue=\"category\",\n",
    "                hue_order=[\"straight\", \"L-shape\", \"fork\", \"cross\"],\n",
    "                sizes=(20, 200),\n",
    "            )\n",
    "            for c in [\"straight\", \"L-shape\", \"fork\", \"cross\"]:\n",
    "                gpd = result_df[result_df.category == c]\n",
    "                ax.errorbar(\n",
    "                    gpd[\"local_4dirs_diff\"],\n",
    "                    gpd[\"mean\"],\n",
    "                    yerr=gpd[\"std\"] / np.sqrt(gpd[\"count\"]),\n",
    "                    marker=None,\n",
    "                    capsize=3,\n",
    "                )\n",
    "            ax.legend()\n",
    "            ax.set_xticks([0, 1, 2, 3, 4])\n",
    "            ax.set_xticklabels([0, 1, 2, 3, \">=4\"])\n",
    "            ax.set_xlabel(\"local reward max - 2nd max\")\n",
    "            ax.set_ylabel(\"% of toward the most valuable direction\")\n",
    "            ax.set_title(\"errorbar = traditional std\")\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.figure.savefig(save_path)\n",
    "        else:\n",
    "            errorplot = ax.errorbar(\n",
    "                result_df[result_df.category == land][\"local_4dirs_diff\"],\n",
    "                result_df[result_df.category == land][\"mean\"],\n",
    "                #         yerr=result_df[\"std\"] / np.sqrt(result_df[\"count\"]),\n",
    "                marker=\"o\",\n",
    "                #         capsize=3,\n",
    "            )\n",
    "            pp.append(errorplot.lines[0])\n",
    "\n",
    "            # use them in the legend\n",
    "            ax.legend(pp, [str(i) for i in [1, 3, 5, 7]], ncol=4, numpoints=1)\n",
    "            ax.set_xticks([0, 1, 2, 3, 4])\n",
    "            ax.set_xticklabels([0, 1, 2, 3, \">=4\"])\n",
    "            plt.xlabel(\"local reward max - 2nd max\")\n",
    "            plt.ylabel(\"% of toward the most valuable direction\")\n",
    "            plt.title(land.capitalize() + \" Local Graze\")\n",
    "            plt.savefig(save_path)\n",
    "\n",
    "\n",
    "def add_PEG_dis(df_total):\n",
    "    diss = add_dis(\n",
    "        add_dis(\n",
    "            add_dis(\n",
    "                df_total[\n",
    "                    [\"ghost2Pos\", \"ghost1Pos\", \"next_eat_energizer\", \"pacmanPos\"]\n",
    "                ].reset_index(),\n",
    "                \"pacmanPos\",\n",
    "                \"next_eat_energizer\",\n",
    "                \"PE_dis\",\n",
    "            ),\n",
    "            \"next_eat_energizer\",\n",
    "            \"ghost1Pos\",\n",
    "            \"EG1_dis\",\n",
    "        ),\n",
    "        \"next_eat_energizer\",\n",
    "        \"ghost2Pos\",\n",
    "        \"EG2_dis\",\n",
    "    )\n",
    "\n",
    "    diss[\"EG_dis\"] = diss[[\"EG1_dis\", \"EG2_dis\"]].min(1)\n",
    "\n",
    "    df_total = pd.concat(\n",
    "        [\n",
    "            df_total,\n",
    "            diss.set_index(\"level_0\")[[\"PE_dis\", \"EG_dis\", \"EG1_dis\", \"EG2_dis\"]],\n",
    "        ],\n",
    "        1,\n",
    "    )\n",
    "    return df_total\n",
    "\n",
    "\n",
    "def count_change_dir(x):\n",
    "    \"\"\"x: [[(1,2),(4,5)]]\"\"\"\n",
    "    df_temp = pd.DataFrame(x).T.reset_index()\n",
    "    move_dir = add_move_dir(df_temp, 0, \"move_dir\", direction=1).move_dir.explode()\n",
    "    return (move_dir.fillna(method=\"bfill\") != move_dir.fillna(method=\"bfill\").shift())[\n",
    "        1:\n",
    "    ].sum()\n",
    "\n",
    "\n",
    "def generate_cons(df_total):\n",
    "    cons_list_accident = (\n",
    "        df_total[df_total.status == \"local\"]\n",
    "        .groupby(\"file\")\n",
    "        .apply(lambda x: x.index.tolist())\n",
    "        .reset_index()[0]\n",
    "    )\n",
    "    cons_list_plan = (\n",
    "        df_total[df_total.status == \"planned_hunting\"]\n",
    "        .groupby(\"file\")\n",
    "        .apply(lambda x: x.index.tolist())\n",
    "        .reset_index()[0]\n",
    "    )\n",
    "    return cons_list_accident, cons_list_plan\n",
    "\n",
    "\n",
    "def add_nearest_rwd_reset(df_total):\n",
    "    \"\"\"\n",
    "    对每一步添加最近的点(有可能是多个点，所以对于每个点return的是一个list)\n",
    "    \"\"\"\n",
    "    tmp = add_dis(\n",
    "        df_total[[\"beans\", \"file\", \"index\"]]\n",
    "        .assign(reset_pos=[(14, 27)] * df_total.shape[0])\n",
    "        .explode(\"beans\"),\n",
    "        \"reset_pos\",\n",
    "        \"beans\",\n",
    "    )\n",
    "    tmp = (\n",
    "        tmp.merge(\n",
    "            tmp.groupby([\"file\", \"index\"]).dis.min().reset_index(),\n",
    "            on=[\"dis\", \"file\", \"index\"],\n",
    "        )\n",
    "        .groupby([\"file\", \"index\", \"dis\"])\n",
    "        .apply(lambda x: list(x.beans))\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"nearresetPos\", \"dis\": \"rwd_reset_distance\"})\n",
    "    )\n",
    "\n",
    "    return df_total.merge(tmp, on=[\"file\", \"index\"], how=\"left\")\n",
    "\n",
    "\n",
    "def label_hunts(df_model):\n",
    "    hunt_index1 = (\n",
    "        ((df_model.status_e1 == 0) & (df_model.status_h1 == 1))\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    hunt_index2 = (\n",
    "        ((df_model.status_e2 == 0) & (df_model.status_h2 == 1))\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "    prehunt_index = (\n",
    "        ((df_model.status_h1 == -1) | (df_model.status_h2 == -1))\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "    df_model.loc[hunt_index1, \"label_hunt1\"] = 1\n",
    "    df_model.loc[hunt_index2, \"label_hunt2\"] = 1\n",
    "    df_model.loc[prehunt_index, \"label_prehunt\"] = 1\n",
    "\n",
    "\n",
    "def plot_eating(df_pos, idx, reward_sel):\n",
    "    f, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(ARRAY, ax=ax, linewidth=0.5, annot=False, cbar=False, cmap=\"bone\")\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    ax.set_title(df_pos.file.values[0])\n",
    "\n",
    "    plt.scatter(\n",
    "        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward <= 2)].X + 0.5,\n",
    "        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward <= 2)].Y + 0.5,\n",
    "        color=\"brown\",\n",
    "        s=reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward <= 2)].Reward * 70,\n",
    "        marker=get_marker(SYMBOLS[\"cookie\"]),\n",
    "    )\n",
    "    plt.scatter(\n",
    "        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward > 2)].X + 0.5,\n",
    "        reward_sel[(reward_sel.Step == idx) & (reward_sel.Reward > 2)].Y + 0.5,\n",
    "        color=\"red\",\n",
    "        s=120,\n",
    "        marker=get_marker(SYMBOLS[\"apple\"]),\n",
    "    )\n",
    "    plt.scatter(\n",
    "        np.array(df_pos.loc[idx, \"pacmanPos\"])[0] + 0.5,\n",
    "        np.array(df_pos.loc[idx, \"pacmanPos\"])[1] + 0.5,\n",
    "        marker=get_marker(SYMBOLS[\"monkey\"]),\n",
    "        s=300,\n",
    "        color=\"green\",\n",
    "    )  # pacman\n",
    "\n",
    "    #     plt.text(\n",
    "    #         x=40,\n",
    "    #         y=6,\n",
    "    #         s=\"global_Q: \" + str(df_pos.loc[idx, \"global_Q\"]),\n",
    "    #         horizontalalignment=\"right\",\n",
    "    #     )\n",
    "    #     plt.text(\n",
    "    #         x=40,\n",
    "    #         y=7,\n",
    "    #         s=\"local_Q: \" + str(df_pos.loc[idx, \"local_Q\"]),\n",
    "    #         horizontalalignment=\"right\",\n",
    "    #     )\n",
    "    #     plt.text(\n",
    "    #         x=40,\n",
    "    #         y=8,\n",
    "    #         s=\"pess_Q: \" + str(df_pos.loc[idx, \"pessimistic_Q\"]),\n",
    "    #         horizontalalignment=\"right\",\n",
    "    #     )\n",
    "\n",
    "    plt.text(\n",
    "        x=40,\n",
    "        y=9,\n",
    "        #         s=\"current index: \" + str(idx + df_pos[\"index\"].values[0]),\n",
    "        s=\"current index: \" + str(idx),\n",
    "        horizontalalignment=\"right\",\n",
    "    )\n",
    "    plt.text(\n",
    "        x=40,\n",
    "        y=10,\n",
    "        s=\"handcraft_label: \" + \", \".join(np.ravel(df_pos.loc[0, \"fitted_label\"])),\n",
    "        horizontalalignment=\"right\",\n",
    "    )\n",
    "    plt.text(\n",
    "        x=40,\n",
    "        y=11,\n",
    "        s=\"estimated_label: \" + \", \".join(np.ravel(df_pos.loc[0, \"rulebased_label\"])),\n",
    "        horizontalalignment=\"right\",\n",
    "    )\n",
    "    for cnt, i in enumerate(\n",
    "        [\"global\", \"local\", \"evade(Blinky)\", \"evade(Clyde)\", \"approach\", \"energizer\"]\n",
    "    ):\n",
    "        plt.text(\n",
    "            x=40,\n",
    "            y=12 + cnt,\n",
    "            s=i + \": \" + str(np.round(df_pos.loc[idx, i + \"_weight\"], 2)),\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "\n",
    "    if df_pos.loc[idx, \"ifscared1\"] < 3:\n",
    "        plt.scatter(\n",
    "            np.array(df_pos.loc[idx, \"ghost1Pos\"])[0] + 0.5,\n",
    "            np.array(df_pos.loc[idx, \"ghost1Pos\"])[1] + 0.5,\n",
    "            marker=get_marker(SYMBOLS[\"ghost\"]),\n",
    "            s=300,\n",
    "            color=\"red\",\n",
    "        )  # normal ghost\n",
    "    elif df_pos.loc[idx, \"ifscared1\"] >= 4:\n",
    "        plt.scatter(\n",
    "            np.array(df_pos.loc[idx, \"ghost1Pos\"])[0] + 0.5,\n",
    "            np.array(df_pos.loc[idx, \"ghost1Pos\"])[1] + 0.5,\n",
    "            marker=get_marker(SYMBOLS[\"ghost\"]),\n",
    "            s=300,\n",
    "            color=\"white\",\n",
    "            edgecolor=\"red\",\n",
    "        )  # scared + flashing ghost\n",
    "    else:\n",
    "        plt.scatter(\n",
    "            np.array(df_pos.loc[idx, \"ghost1Pos\"])[0] + 0.5,\n",
    "            np.array(df_pos.loc[idx, \"ghost1Pos\"])[1] + 0.5,\n",
    "            marker=get_marker(SYMBOLS[\"eye\"]),\n",
    "            s=30,\n",
    "            color=\"white\",\n",
    "            edgecolor=\"black\",  # dead ghost\n",
    "        )\n",
    "    if df_pos.loc[idx, \"ifscared2\"] < 3:\n",
    "        plt.scatter(\n",
    "            np.array(df_pos.loc[idx, \"ghost2Pos\"])[0] + 0.5,\n",
    "            np.array(df_pos.loc[idx, \"ghost2Pos\"])[1] + 0.5,\n",
    "            marker=get_marker(SYMBOLS[\"ghost\"]),\n",
    "            s=300,\n",
    "            color=\"orange\",\n",
    "        )  # normal ghost\n",
    "    elif df_pos.loc[idx, \"ifscared2\"] >= 4:\n",
    "        plt.scatter(\n",
    "            np.array(df_pos.loc[idx, \"ghost2Pos\"])[0] + 0.5,\n",
    "            np.array(df_pos.loc[idx, \"ghost2Pos\"])[1] + 0.5,\n",
    "            marker=get_marker(SYMBOLS[\"ghost\"]),\n",
    "            s=300,\n",
    "            color=\"white\",\n",
    "            edgecolor=\"orange\",\n",
    "        )  # scared + flashing ghost\n",
    "    else:\n",
    "        plt.scatter(\n",
    "            np.array(df_pos.loc[idx, \"ghost2Pos\"])[0] + 0.5,\n",
    "            np.array(df_pos.loc[idx, \"ghost2Pos\"])[1] + 0.5,\n",
    "            marker=get_marker(SYMBOLS[\"eye\"]),\n",
    "            s=30,\n",
    "            color=\"white\",\n",
    "            edgecolor=\"black\",  # dead ghost\n",
    "        )\n",
    "\n",
    "\n",
    "def generate_qtable(df_output, filename, window_size=3):\n",
    "    Q_table = pd.DataFrame()\n",
    "    file_data = [j for j in df_output if j[-1] == filename][0]\n",
    "    set_trace()\n",
    "    for start_index, sub in enumerate(file_data[4].round(2)):\n",
    "        df_temp = pd.concat(\n",
    "            [\n",
    "                pd.Series([list(i[0]), list(i[1])], index=[\"local_Q\", \"pessimistic_Q\"],)\n",
    "                for i in sub\n",
    "            ],\n",
    "            1,\n",
    "        ).T\n",
    "        df_temp.index = range(start_index, start_index + 2 * window_size + 1)\n",
    "        Q_table = Q_table.append(df_temp)\n",
    "    Q_table = (\n",
    "        Q_table[~Q_table.index.duplicated(keep=\"first\")][window_size:-window_size]\n",
    "        .reset_index()\n",
    "        .drop(\"index\", 1)\n",
    "    )\n",
    "    return Q_table\n",
    "\n",
    "\n",
    "def add_pess(x):\n",
    "    if x.estimated_label == [\"pessimistic\"]:\n",
    "        return x.estimated_label\n",
    "    if x.estimated_label != [\"\"]:\n",
    "        if x.pessimistic_weight > 0.5:\n",
    "            return [x.estimated_label[0], \"pessimistic\"]\n",
    "        else:\n",
    "            return x.estimated_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 全局常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"params = {\\n    \\\"legend.fontsize\\\": 14,\\n    \\\"legend.frameon\\\": False,\\n    \\\"ytick.labelsize\\\": 14,\\n    \\\"xtick.labelsize\\\": 14,\\n    \\\"figure.dpi\\\": 300,\\n    \\\"axes.prop_cycle\\\": plt.cycler(\\\"color\\\", plt.cm.tab20b(np.linspace(0, 1, 4))),\\n    \\\"axes.labelsize\\\": 14,\\n    \\\"axes.titlesize\\\": 14,\\n    \\\"pdf.fonttype\\\": 42,\\n    \\\"font.sans-serif\\\": \\\"Myriad Pro\\\",\\n    \\\"font.family\\\": \\\"sans-serif\\\",\\n}\\nplt.rcParams.update(params)\\ncolormapping = {\\\"1\\\": \\\"firebrick\\\", \\\"2\\\": \\\"khaki\\\"}\\n\\n\\\"\\\"\\\"\\u7ed9result_df\\u52a0\\u4e0a\\u7c7b\\u522b\\u7684label\\\"\\\"\\\"\\ncate_df = pd.DataFrame(\\n    [\\n        [2, False, \\\"straight\\\"],\\n        [2, True, \\\"L-shape\\\"],\\n        [3, True, \\\"fork\\\"],\\n        [4, True, \\\"cross\\\"],\\n    ],\\n    columns=[\\\"NextNum\\\", \\\"if_cross\\\", \\\"category\\\"],\\n)\\n\\\"\\\"\\\"\\u4e3a\\u6bcf\\u4e2a\\u8fd0\\u52a8\\u65b9\\u5411\\u9009\\u62e9\\u5411\\u5de6\\u7684\\u65b9\\u5411\\\"\\\"\\\"\\nleft_turn_mapping = {\\\"right\\\": \\\"up\\\", \\\"up\\\": \\\"left\\\", \\\"left\\\": \\\"down\\\", \\\"down\\\": \\\"right\\\"}\\n\\nsshape = [\\n    (10, 12),\\n    (10, 30),\\n    (13, 12),\\n    (13, 30),\\n    (16, 12),\\n    (16, 30),\\n    (19, 12),\\n    (19, 30),\\n]\\ndelays_up = [(13, 5), (16, 5)]\\ndelays_down = [(7, 30), (22, 30)]\\noutside = [(2, 5), (2, 24), (2, 12), (2, 33), (27, 5), (27, 24), (27, 12), (27, 33)]\\n\\ncentral = [\\n    i for i in TURNING_POS if i[0] <= 19 and i[0] >= 10 and i[1] >= 15 and i[1] <= 24\\n]\\ncentral = list(set(central) - set([(14, 15), (15, 15)]))\\n\\nred_pos = [i for i in TURNING_POS if i[0] in [2, 27]] + [\\n    (7, 24),\\n    (7, 18),\\n    (7, 9),\\n    (22, 24),\\n    (22, 18),\\n    (22, 9),\\n]\\n\\nblue_pos = list(set(TURNING_POS) - set(red_pos))\\n\\nstate_color = {\\n    \\\"global graze\\\": plt.cm.Set1.colors[1],\\n    \\\"local graze in scared mode\\\": plt.cm.Set1.colors[0],\\n    \\\"local graze in normal mode\\\": plt.cm.Set1.colors[0],\\n    \\\"hunt\\\": plt.cm.Set1.colors[3],\\n    \\\"evade\\\": plt.cm.Set1.colors[0],\\n    \\\"suicide\\\": plt.cm.Set1.colors[1],\\n    \\\"accidentally hunt\\\": plt.cm.Set1.colors[0],\\n    \\\"planning hunt\\\": plt.cm.Set1.colors[1],\\n}\";\n",
       "                var nbb_formatted_code = \"params = {\\n    \\\"legend.fontsize\\\": 14,\\n    \\\"legend.frameon\\\": False,\\n    \\\"ytick.labelsize\\\": 14,\\n    \\\"xtick.labelsize\\\": 14,\\n    \\\"figure.dpi\\\": 300,\\n    \\\"axes.prop_cycle\\\": plt.cycler(\\\"color\\\", plt.cm.tab20b(np.linspace(0, 1, 4))),\\n    \\\"axes.labelsize\\\": 14,\\n    \\\"axes.titlesize\\\": 14,\\n    \\\"pdf.fonttype\\\": 42,\\n    \\\"font.sans-serif\\\": \\\"Myriad Pro\\\",\\n    \\\"font.family\\\": \\\"sans-serif\\\",\\n}\\nplt.rcParams.update(params)\\ncolormapping = {\\\"1\\\": \\\"firebrick\\\", \\\"2\\\": \\\"khaki\\\"}\\n\\n\\\"\\\"\\\"\\u7ed9result_df\\u52a0\\u4e0a\\u7c7b\\u522b\\u7684label\\\"\\\"\\\"\\ncate_df = pd.DataFrame(\\n    [\\n        [2, False, \\\"straight\\\"],\\n        [2, True, \\\"L-shape\\\"],\\n        [3, True, \\\"fork\\\"],\\n        [4, True, \\\"cross\\\"],\\n    ],\\n    columns=[\\\"NextNum\\\", \\\"if_cross\\\", \\\"category\\\"],\\n)\\n\\\"\\\"\\\"\\u4e3a\\u6bcf\\u4e2a\\u8fd0\\u52a8\\u65b9\\u5411\\u9009\\u62e9\\u5411\\u5de6\\u7684\\u65b9\\u5411\\\"\\\"\\\"\\nleft_turn_mapping = {\\\"right\\\": \\\"up\\\", \\\"up\\\": \\\"left\\\", \\\"left\\\": \\\"down\\\", \\\"down\\\": \\\"right\\\"}\\n\\nsshape = [\\n    (10, 12),\\n    (10, 30),\\n    (13, 12),\\n    (13, 30),\\n    (16, 12),\\n    (16, 30),\\n    (19, 12),\\n    (19, 30),\\n]\\ndelays_up = [(13, 5), (16, 5)]\\ndelays_down = [(7, 30), (22, 30)]\\noutside = [(2, 5), (2, 24), (2, 12), (2, 33), (27, 5), (27, 24), (27, 12), (27, 33)]\\n\\ncentral = [\\n    i for i in TURNING_POS if i[0] <= 19 and i[0] >= 10 and i[1] >= 15 and i[1] <= 24\\n]\\ncentral = list(set(central) - set([(14, 15), (15, 15)]))\\n\\nred_pos = [i for i in TURNING_POS if i[0] in [2, 27]] + [\\n    (7, 24),\\n    (7, 18),\\n    (7, 9),\\n    (22, 24),\\n    (22, 18),\\n    (22, 9),\\n]\\n\\nblue_pos = list(set(TURNING_POS) - set(red_pos))\\n\\nstate_color = {\\n    \\\"global graze\\\": plt.cm.Set1.colors[1],\\n    \\\"local graze in scared mode\\\": plt.cm.Set1.colors[0],\\n    \\\"local graze in normal mode\\\": plt.cm.Set1.colors[0],\\n    \\\"hunt\\\": plt.cm.Set1.colors[3],\\n    \\\"evade\\\": plt.cm.Set1.colors[0],\\n    \\\"suicide\\\": plt.cm.Set1.colors[1],\\n    \\\"accidentally hunt\\\": plt.cm.Set1.colors[0],\\n    \\\"planning hunt\\\": plt.cm.Set1.colors[1],\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"legend.frameon\": False,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"figure.dpi\": 300,\n",
    "    \"axes.prop_cycle\": plt.cycler(\"color\", plt.cm.tab20b(np.linspace(0, 1, 4))),\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"pdf.fonttype\": 42,\n",
    "    \"font.sans-serif\": \"Myriad Pro\",\n",
    "    \"font.family\": \"sans-serif\",\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "colormapping = {\"1\": \"firebrick\", \"2\": \"khaki\"}\n",
    "\n",
    "\"\"\"给result_df加上类别的label\"\"\"\n",
    "cate_df = pd.DataFrame(\n",
    "    [\n",
    "        [2, False, \"straight\"],\n",
    "        [2, True, \"L-shape\"],\n",
    "        [3, True, \"fork\"],\n",
    "        [4, True, \"cross\"],\n",
    "    ],\n",
    "    columns=[\"NextNum\", \"if_cross\", \"category\"],\n",
    ")\n",
    "\"\"\"为每个运动方向选择向左的方向\"\"\"\n",
    "left_turn_mapping = {\"right\": \"up\", \"up\": \"left\", \"left\": \"down\", \"down\": \"right\"}\n",
    "\n",
    "sshape = [\n",
    "    (10, 12),\n",
    "    (10, 30),\n",
    "    (13, 12),\n",
    "    (13, 30),\n",
    "    (16, 12),\n",
    "    (16, 30),\n",
    "    (19, 12),\n",
    "    (19, 30),\n",
    "]\n",
    "delays_up = [(13, 5), (16, 5)]\n",
    "delays_down = [(7, 30), (22, 30)]\n",
    "outside = [(2, 5), (2, 24), (2, 12), (2, 33), (27, 5), (27, 24), (27, 12), (27, 33)]\n",
    "\n",
    "central = [\n",
    "    i for i in TURNING_POS if i[0] <= 19 and i[0] >= 10 and i[1] >= 15 and i[1] <= 24\n",
    "]\n",
    "central = list(set(central) - set([(14, 15), (15, 15)]))\n",
    "\n",
    "red_pos = [i for i in TURNING_POS if i[0] in [2, 27]] + [\n",
    "    (7, 24),\n",
    "    (7, 18),\n",
    "    (7, 9),\n",
    "    (22, 24),\n",
    "    (22, 18),\n",
    "    (22, 9),\n",
    "]\n",
    "\n",
    "blue_pos = list(set(TURNING_POS) - set(red_pos))\n",
    "\n",
    "state_color = {\n",
    "    \"global graze\": plt.cm.Set1.colors[1],\n",
    "    \"local graze in scared mode\": plt.cm.Set1.colors[0],\n",
    "    \"local graze in normal mode\": plt.cm.Set1.colors[0],\n",
    "    \"hunt\": plt.cm.Set1.colors[3],\n",
    "    \"evade\": plt.cm.Set1.colors[0],\n",
    "    \"suicide\": plt.cm.Set1.colors[1],\n",
    "    \"accidentally hunt\": plt.cm.Set1.colors[0],\n",
    "    \"planning hunt\": plt.cm.Set1.colors[1],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取全数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_small = pd.read_pickle(\"../constants/simulated_total.pkl\")\n",
    "with open(\"../constants/df_overlap_simulated.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        generate_simulated_local_4dirs(df_total_small, \"beans\", joinon=\"pacmanPos\"), f\n",
    "    )\n",
    "label_hunts(df_total_small)\n",
    "\n",
    "cons_list_accident, cons_list_plan = (\n",
    "    status_index(\n",
    "        df_total_small[df_total_small.status == \"local_on_accidental_three_record\"]\n",
    "    )[0],\n",
    "    pd.Series(\n",
    "        status_index(df_total_small[df_total_small.status == \"planned_hunting_record\"])[\n",
    "            2\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"dall = pickle.load(open(\\\"../constants/all_data_new.pkl\\\", \\\"rb\\\"))\\n\\nlocals().update(dall)\\n\\n# \\\"\\\"\\\"\\u6309\\u7167\\u6bcf\\u4e2agame\\u7684\\u5e73\\u5747pupil size\\u4f5c\\u4e3abaseline\\uff0c\\u7b97\\u51faeye_size_std2\\\"\\\"\\\"\\n# df_total = (\\n#     df_total.reset_index()\\n#     .merge(\\n#         df_total.groupby(\\\"game\\\")\\n#         .eye_size.mean()\\n#         .rename(\\\"eye_size_basegame\\\")\\n#         .reset_index(),\\n#         on=\\\"game\\\",\\n#         how=\\\"left\\\",\\n#     )\\n#     .set_index(\\\"level_0\\\")\\n# )\\n# df_total[\\\"eye_size_std2\\\"] = df_total.eye_size - df_total.eye_size_basegame\";\n",
       "                var nbb_formatted_code = \"dall = pickle.load(open(\\\"../constants/all_data_new.pkl\\\", \\\"rb\\\"))\\n\\nlocals().update(dall)\\n\\n# \\\"\\\"\\\"\\u6309\\u7167\\u6bcf\\u4e2agame\\u7684\\u5e73\\u5747pupil size\\u4f5c\\u4e3abaseline\\uff0c\\u7b97\\u51faeye_size_std2\\\"\\\"\\\"\\n# df_total = (\\n#     df_total.reset_index()\\n#     .merge(\\n#         df_total.groupby(\\\"game\\\")\\n#         .eye_size.mean()\\n#         .rename(\\\"eye_size_basegame\\\")\\n#         .reset_index(),\\n#         on=\\\"game\\\",\\n#         how=\\\"left\\\",\\n#     )\\n#     .set_index(\\\"level_0\\\")\\n# )\\n# df_total[\\\"eye_size_std2\\\"] = df_total.eye_size - df_total.eye_size_basegame\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dall = pickle.load(open(\"../constants/all_data_new.pkl\", \"rb\"))\n",
    "\n",
    "locals().update(dall)\n",
    "\n",
    "# \"\"\"按照每个game的平均pupil size作为baseline，算出eye_size_std2\"\"\"\n",
    "# df_total = (\n",
    "#     df_total.reset_index()\n",
    "#     .merge(\n",
    "#         df_total.groupby(\"game\")\n",
    "#         .eye_size.mean()\n",
    "#         .rename(\"eye_size_basegame\")\n",
    "#         .reset_index(),\n",
    "#         on=\"game\",\n",
    "#         how=\"left\",\n",
    "#     )\n",
    "#     .set_index(\"level_0\")\n",
    "# )\n",
    "# df_total[\"eye_size_std2\"] = df_total.eye_size - df_total.eye_size_basegame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_fruit(x):\n",
    "    if x.fruitPos.isnull().sum() == x.shape[0]:\n",
    "        return x\n",
    "    x.fruitPos = x.fruitPos.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    x.beans = x.apply(\n",
    "        lambda x: list(set(set([x.fruitPos]) | set(x.beans)))\n",
    "        if not isinstance(x.beans, float)\n",
    "        else [x.fruitPos],\n",
    "        1,\n",
    "    )\n",
    "    if x[x.pacmanPos == x.fruitPos].shape[0] > 0:\n",
    "        na_start = x[x.pacmanPos == x.fruitPos].index.values[0] + 1\n",
    "        if na_start in x.index:\n",
    "            x.loc[na_start - 1 :, \"beans\"] = x.apply(\n",
    "                lambda x: list(set(x.beans) - set([x.fruitPos])), 1\n",
    "            )\n",
    "            x.loc[na_start:, \"fruitPos\"] = np.nan\n",
    "    return x\n",
    "\n",
    "df_sub = (\n",
    "    df_total.assign(inttrial=df_total.game_trial.astype(int))\n",
    "    .reset_index()\n",
    "    .sort_values(by=[\"game\", \"inttrial\", \"index\"])\n",
    "    .rename(columns={\"level_0\": \"need_back\"})\n",
    "    .reset_index()\n",
    "    .drop(\"level_0\", 1)\n",
    "    .groupby(\"game\")\n",
    "    .apply(lambda x: revise_fruit(x))\n",
    "    .set_index(\"need_back\")\n",
    "    .drop(\"inttrial\", 1)\n",
    ")\n",
    "\n",
    "\"更新df_total\"\n",
    "dall[\"df_total\"] = df_sub\n",
    "\n",
    "with open(\"../constants/all_data_new.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\n",
    "#     \"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/equal_records1.npy\",\n",
    "#     [[file_list[i]] + list(df_output[i]) for i in range(94)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"window_size = 3\\nwindow_size_pad = 3\\nfor filename in [\\n    \\\"equal_records.npy\\\",\\n]:\\n    df_output = np.load(\\n        \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/\\\" + filename,\\n        allow_pickle=True,\\n    )\\n    #     df_output = [[i[1:] if type(i) != str else i for i in j] for j in df_output]\\n    file_list = [f[-1] for f in df_output]\\n    produced = [i[:-4].split(\\\"_\\\")[-1] for i in os.listdir(\\\".\\\")]\\n    # trial name,\\n    # global + local + pessimistic + intercept weight,\\n    # global + local + pessimistic weight*Q scale\\uff0c\\n    # estimated labels,\\n    # hand-crafted labels\\n    \\\"\\u52a8\\u6001\\u56fe(\\u6d4b\\u8bd5)\\\"\\n    for i in list(set(file_list) - set(produced)):\\n        plt.rcParams[\\\"figure.dpi\\\"] = 100\\n        df_explore = (\\n            df_total[\\n                (df_total.file == i.split(\\\".\\\")[0] + \\\".csv\\\")\\n                #                 & (\\n                #                     df_total[\\\"index\\\"].between(\\n                #                         *[j[-1] for j in df_output if j[0] == i][0]\\n                #                     )\\n                #                 )\\n            ]\\n            .reset_index()\\n            .drop(\\\"level_0\\\", 1)\\n        )\\n        cols = [\\n            \\\"global_weight\\\",\\n            \\\"local_weight\\\",\\n            \\\"evade(Blinky)_weight\\\",\\n            \\\"evade(Clyde)_weight\\\",\\n            \\\"approach_weight\\\",\\n            \\\"energizer_weight\\\",\\n        ]\\n        if [j[0].shape[0] for j in df_output if j[-1] == i][0] <= 1:\\n            continue\\n        df_explore = pd.concat(\\n            [\\n                df_explore,\\n                pd.DataFrame(\\n                    np.concatenate(\\n                        [\\n                            np.zeros([window_size_pad, len(cols)]),\\n                            [j[1] for j in df_output if j[-1] == i][0],\\n                            np.zeros([window_size_pad, len(cols)]),\\n                        ],\\n                    ),\\n                    columns=cols,\\n                ),\\n                pd.DataFrame(\\n                    pd.Series(\\n                        [np.nan] * window_size_pad\\n                        + [j[2] for j in df_output if j[-1] == i][0]\\n                        + [np.nan] * window_size_pad\\n                    )\\n                ).rename(columns={0: \\\"fitted_label\\\"},),\\n                pd.DataFrame(\\n                    pd.Series(\\n                        [np.nan] * window_size_pad\\n                        + [j[3] for j in df_output if j[-1] == i][0]\\n                        + [np.nan] * window_size_pad\\n                    )\\n                ).rename(columns={0: \\\"rulebased_label\\\"},),\\n            ],\\n            1,\\n        )\\n\\n        df_explore.fitted_label = df_explore.fitted_label.apply(\\n            lambda x: [\\\"\\\"] if x is None or isinstance(x, float) else x\\n        )\\n        #         df_explore.estimated_label = df_explore.apply(lambda x: add_pess(x), 1,)\\n        df_explore.rulebased_label = df_explore.rulebased_label.apply(\\n            lambda x: [\\\"\\\"] if x is None or isinstance(x, float) else x\\n        )\\n        #         Q_table = generate_qtable(df_output, i, window_size=window_size)\\n        #         df_explore = pd.concat([df_explore, Q_table], 1)\\n        reward_sel = (\\n            pd.concat(\\n                [\\n                    df_explore.reset_index()\\n                    .energizers.explode()\\n                    .dropna()\\n                    .apply(lambda x: pd.Series([x[0], x[1]], index=[\\\"X\\\", \\\"Y\\\"]))\\n                    .reset_index()\\n                    .assign(Reward=2),\\n                    df_explore.reset_index()\\n                    .beans.explode()\\n                    .dropna()\\n                    .apply(lambda x: pd.Series([x[0], x[1]], index=[\\\"X\\\", \\\"Y\\\"]))\\n                    .reset_index()\\n                    .assign(Reward=1),\\n                    df_explore.reset_index()\\n                    .fruitPos.dropna()\\n                    .apply(lambda x: pd.Series([x[0], x[1]], index=[\\\"X\\\", \\\"Y\\\"]))\\n                    .reset_index()\\n                    .assign(Reward=3),\\n                ]\\n            )\\n            .rename(columns={\\\"index\\\": \\\"Step\\\"})\\n            .sort_values(\\\"Step\\\")\\n        )\\n        # w = interact(\\n        #     plot_eating,\\n        #     df_pos=fixed(df_explore),\\n        #     reward_sel=fixed(reward_sel),\\n        #     idx=(\\n        #         widgets.IntSlider(\\n        #             min=df_explore.index.min(), max=df_explore.index.max(), step=1, value=3,\\n        #         )\\n        #     ),\\n        # )\\n\\n        for f in os.listdir(\\n            \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/\\\"\\n        ):\\n            if f[0] != \\\".\\\":\\n                os.remove(\\n                    \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/\\\"\\n                    + f\\n                )\\n        for idx in range(df_explore.shape[0]):\\n            plot_eating(df_explore, idx, reward_sel)\\n            plt.savefig(\\n                \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/\\\"\\n                + str(idx).zfill(3)\\n                + \\\".png\\\",\\n                bbox_inches=\\\"tight\\\",\\n            )\\n            plt.close()\\n\\n        subprocess.call(\\n            'ffmpeg -framerate 3 -start_number 0 -s 1087x827 -i \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/%03d.png\\\" -c:v libx264 -vf \\\"fps=25,scale=1920:1080,format=yuv420p\\\" '\\n            + filename.split(\\\"_\\\")[1]\\n            + \\\"_\\\"\\n            + i\\n            + \\\".mp4\\\",\\n            shell=True,\\n        )\\n        gc.collect()\";\n",
       "                var nbb_formatted_code = \"window_size = 3\\nwindow_size_pad = 3\\nfor filename in [\\n    \\\"equal_records.npy\\\",\\n]:\\n    df_output = np.load(\\n        \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/\\\" + filename,\\n        allow_pickle=True,\\n    )\\n    #     df_output = [[i[1:] if type(i) != str else i for i in j] for j in df_output]\\n    file_list = [f[-1] for f in df_output]\\n    produced = [i[:-4].split(\\\"_\\\")[-1] for i in os.listdir(\\\".\\\")]\\n    # trial name,\\n    # global + local + pessimistic + intercept weight,\\n    # global + local + pessimistic weight*Q scale\\uff0c\\n    # estimated labels,\\n    # hand-crafted labels\\n    \\\"\\u52a8\\u6001\\u56fe(\\u6d4b\\u8bd5)\\\"\\n    for i in list(set(file_list) - set(produced)):\\n        plt.rcParams[\\\"figure.dpi\\\"] = 100\\n        df_explore = (\\n            df_total[\\n                (df_total.file == i.split(\\\".\\\")[0] + \\\".csv\\\")\\n                #                 & (\\n                #                     df_total[\\\"index\\\"].between(\\n                #                         *[j[-1] for j in df_output if j[0] == i][0]\\n                #                     )\\n                #                 )\\n            ]\\n            .reset_index()\\n            .drop(\\\"level_0\\\", 1)\\n        )\\n        cols = [\\n            \\\"global_weight\\\",\\n            \\\"local_weight\\\",\\n            \\\"evade(Blinky)_weight\\\",\\n            \\\"evade(Clyde)_weight\\\",\\n            \\\"approach_weight\\\",\\n            \\\"energizer_weight\\\",\\n        ]\\n        if [j[0].shape[0] for j in df_output if j[-1] == i][0] <= 1:\\n            continue\\n        df_explore = pd.concat(\\n            [\\n                df_explore,\\n                pd.DataFrame(\\n                    np.concatenate(\\n                        [\\n                            np.zeros([window_size_pad, len(cols)]),\\n                            [j[1] for j in df_output if j[-1] == i][0],\\n                            np.zeros([window_size_pad, len(cols)]),\\n                        ],\\n                    ),\\n                    columns=cols,\\n                ),\\n                pd.DataFrame(\\n                    pd.Series(\\n                        [np.nan] * window_size_pad\\n                        + [j[2] for j in df_output if j[-1] == i][0]\\n                        + [np.nan] * window_size_pad\\n                    )\\n                ).rename(columns={0: \\\"fitted_label\\\"},),\\n                pd.DataFrame(\\n                    pd.Series(\\n                        [np.nan] * window_size_pad\\n                        + [j[3] for j in df_output if j[-1] == i][0]\\n                        + [np.nan] * window_size_pad\\n                    )\\n                ).rename(columns={0: \\\"rulebased_label\\\"},),\\n            ],\\n            1,\\n        )\\n\\n        df_explore.fitted_label = df_explore.fitted_label.apply(\\n            lambda x: [\\\"\\\"] if x is None or isinstance(x, float) else x\\n        )\\n        #         df_explore.estimated_label = df_explore.apply(lambda x: add_pess(x), 1,)\\n        df_explore.rulebased_label = df_explore.rulebased_label.apply(\\n            lambda x: [\\\"\\\"] if x is None or isinstance(x, float) else x\\n        )\\n        #         Q_table = generate_qtable(df_output, i, window_size=window_size)\\n        #         df_explore = pd.concat([df_explore, Q_table], 1)\\n        reward_sel = (\\n            pd.concat(\\n                [\\n                    df_explore.reset_index()\\n                    .energizers.explode()\\n                    .dropna()\\n                    .apply(lambda x: pd.Series([x[0], x[1]], index=[\\\"X\\\", \\\"Y\\\"]))\\n                    .reset_index()\\n                    .assign(Reward=2),\\n                    df_explore.reset_index()\\n                    .beans.explode()\\n                    .dropna()\\n                    .apply(lambda x: pd.Series([x[0], x[1]], index=[\\\"X\\\", \\\"Y\\\"]))\\n                    .reset_index()\\n                    .assign(Reward=1),\\n                    df_explore.reset_index()\\n                    .fruitPos.dropna()\\n                    .apply(lambda x: pd.Series([x[0], x[1]], index=[\\\"X\\\", \\\"Y\\\"]))\\n                    .reset_index()\\n                    .assign(Reward=3),\\n                ]\\n            )\\n            .rename(columns={\\\"index\\\": \\\"Step\\\"})\\n            .sort_values(\\\"Step\\\")\\n        )\\n        # w = interact(\\n        #     plot_eating,\\n        #     df_pos=fixed(df_explore),\\n        #     reward_sel=fixed(reward_sel),\\n        #     idx=(\\n        #         widgets.IntSlider(\\n        #             min=df_explore.index.min(), max=df_explore.index.max(), step=1, value=3,\\n        #         )\\n        #     ),\\n        # )\\n\\n        for f in os.listdir(\\n            \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/\\\"\\n        ):\\n            if f[0] != \\\".\\\":\\n                os.remove(\\n                    \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/\\\"\\n                    + f\\n                )\\n        for idx in range(df_explore.shape[0]):\\n            plot_eating(df_explore, idx, reward_sel)\\n            plt.savefig(\\n                \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/\\\"\\n                + str(idx).zfill(3)\\n                + \\\".png\\\",\\n                bbox_inches=\\\"tight\\\",\\n            )\\n            plt.close()\\n\\n        subprocess.call(\\n            'ffmpeg -framerate 3 -start_number 0 -s 1087x827 -i \\\"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/%03d.png\\\" -c:v libx264 -vf \\\"fps=25,scale=1920:1080,format=yuv420p\\\" '\\n            + filename.split(\\\"_\\\")[1]\\n            + \\\"_\\\"\\n            + i\\n            + \\\".mp4\\\",\\n            shell=True,\\n        )\\n        gc.collect()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 3\n",
    "window_size_pad = 3\n",
    "for filename in [\n",
    "    \"equal_records.npy\",\n",
    "]:\n",
    "    df_output = np.load(\n",
    "        \"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/\" + filename,\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "    #     df_output = [[i[1:] if type(i) != str else i for i in j] for j in df_output]\n",
    "    file_list = [f[-1] for f in df_output]\n",
    "    produced = [i[:-4].split(\"_\")[-1] for i in os.listdir(\".\")]\n",
    "    # trial name,\n",
    "    # global + local + pessimistic + intercept weight,\n",
    "    # global + local + pessimistic weight*Q scale，\n",
    "    # estimated labels,\n",
    "    # hand-crafted labels\n",
    "    \"动态图(测试)\"\n",
    "    for i in list(set(file_list) - set(produced)):\n",
    "        plt.rcParams[\"figure.dpi\"] = 100\n",
    "        df_explore = (\n",
    "            df_total[\n",
    "                (df_total.file == i.split(\".\")[0] + \".csv\")\n",
    "                #                 & (\n",
    "                #                     df_total[\"index\"].between(\n",
    "                #                         *[j[-1] for j in df_output if j[0] == i][0]\n",
    "                #                     )\n",
    "                #                 )\n",
    "            ]\n",
    "            .reset_index()\n",
    "            .drop(\"level_0\", 1)\n",
    "        )\n",
    "        cols = [\n",
    "            \"global_weight\",\n",
    "            \"local_weight\",\n",
    "            \"evade(Blinky)_weight\",\n",
    "            \"evade(Clyde)_weight\",\n",
    "            \"approach_weight\",\n",
    "            \"energizer_weight\",\n",
    "        ]\n",
    "        if [j[0].shape[0] for j in df_output if j[-1] == i][0] <= 1:\n",
    "            continue\n",
    "        df_explore = pd.concat(\n",
    "            [\n",
    "                df_explore,\n",
    "                pd.DataFrame(\n",
    "                    np.concatenate(\n",
    "                        [\n",
    "                            np.zeros([window_size_pad, len(cols)]),\n",
    "                            [j[1] for j in df_output if j[-1] == i][0],\n",
    "                            np.zeros([window_size_pad, len(cols)]),\n",
    "                        ],\n",
    "                    ),\n",
    "                    columns=cols,\n",
    "                ),\n",
    "                pd.DataFrame(\n",
    "                    pd.Series(\n",
    "                        [np.nan] * window_size_pad\n",
    "                        + [j[2] for j in df_output if j[-1] == i][0]\n",
    "                        + [np.nan] * window_size_pad\n",
    "                    )\n",
    "                ).rename(columns={0: \"fitted_label\"},),\n",
    "                pd.DataFrame(\n",
    "                    pd.Series(\n",
    "                        [np.nan] * window_size_pad\n",
    "                        + [j[3] for j in df_output if j[-1] == i][0]\n",
    "                        + [np.nan] * window_size_pad\n",
    "                    )\n",
    "                ).rename(columns={0: \"rulebased_label\"},),\n",
    "            ],\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        df_explore.fitted_label = df_explore.fitted_label.apply(\n",
    "            lambda x: [\"\"] if x is None or isinstance(x, float) else x\n",
    "        )\n",
    "        #         df_explore.estimated_label = df_explore.apply(lambda x: add_pess(x), 1,)\n",
    "        df_explore.rulebased_label = df_explore.rulebased_label.apply(\n",
    "            lambda x: [\"\"] if x is None or isinstance(x, float) else x\n",
    "        )\n",
    "        #         Q_table = generate_qtable(df_output, i, window_size=window_size)\n",
    "        #         df_explore = pd.concat([df_explore, Q_table], 1)\n",
    "        reward_sel = (\n",
    "            pd.concat(\n",
    "                [\n",
    "                    df_explore.reset_index()\n",
    "                    .energizers.explode()\n",
    "                    .dropna()\n",
    "                    .apply(lambda x: pd.Series([x[0], x[1]], index=[\"X\", \"Y\"]))\n",
    "                    .reset_index()\n",
    "                    .assign(Reward=2),\n",
    "                    df_explore.reset_index()\n",
    "                    .beans.explode()\n",
    "                    .dropna()\n",
    "                    .apply(lambda x: pd.Series([x[0], x[1]], index=[\"X\", \"Y\"]))\n",
    "                    .reset_index()\n",
    "                    .assign(Reward=1),\n",
    "                    df_explore.reset_index()\n",
    "                    .fruitPos.dropna()\n",
    "                    .apply(lambda x: pd.Series([x[0], x[1]], index=[\"X\", \"Y\"]))\n",
    "                    .reset_index()\n",
    "                    .assign(Reward=3),\n",
    "                ]\n",
    "            )\n",
    "            .rename(columns={\"index\": \"Step\"})\n",
    "            .sort_values(\"Step\")\n",
    "        )\n",
    "        # w = interact(\n",
    "        #     plot_eating,\n",
    "        #     df_pos=fixed(df_explore),\n",
    "        #     reward_sel=fixed(reward_sel),\n",
    "        #     idx=(\n",
    "        #         widgets.IntSlider(\n",
    "        #             min=df_explore.index.min(), max=df_explore.index.max(), step=1, value=3,\n",
    "        #         )\n",
    "        #     ),\n",
    "        # )\n",
    "\n",
    "        for f in os.listdir(\n",
    "            \"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/\"\n",
    "        ):\n",
    "            if f[0] != \".\":\n",
    "                os.remove(\n",
    "                    \"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/\"\n",
    "                    + f\n",
    "                )\n",
    "        for idx in range(df_explore.shape[0]):\n",
    "            plot_eating(df_explore, idx, reward_sel)\n",
    "            plt.savefig(\n",
    "                \"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/\"\n",
    "                + str(idx).zfill(3)\n",
    "                + \".png\",\n",
    "                bbox_inches=\"tight\",\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "        subprocess.call(\n",
    "            'ffmpeg -framerate 3 -start_number 0 -s 1087x827 -i \"/home/qlyang/jiaqi/Pacman-Analysis/Utility_Tree_Analysis/plot_videos/%03d.png\" -c:v libx264 -vf \"fps=25,scale=1920:1080,format=yuv420p\" '\n",
    "            + filename.split(\"_\")[1]\n",
    "            + \"_\"\n",
    "            + i\n",
    "            + \".mp4\",\n",
    "            shell=True,\n",
    "        )\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "对df_total的数据做修正：\n",
    "新的filename是all_data_new.pkl，\n",
    "修改处：\n",
    "1. label_local_graze, label_local_graze_noghost, label_restl ；\n",
    "2. fruitPos，部分吃掉了之后该列还有数据，已删除做修正；\n",
    "3. 添加label_global_ending数据：在global尾部pacman和要吃的bean之间的距离<=5的情况下，label为1，其他是np.nan\n",
    "\"\"\"\n",
    "\n",
    "def label_status(df_model):\n",
    "    global_graze = (\n",
    "        (\n",
    "            (df_model.status_s != 1)\n",
    "            & (df_model.status_h1 != 1)\n",
    "            & (df_model.status_h2 != 1)\n",
    "            & (df_model.index.isin(global_handler))\n",
    "        )\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    tmp = (\n",
    "        (\n",
    "            (\n",
    "                (\n",
    "                    (df_model.status_e1 == 1)\n",
    "                    & (df_model.distance1 <= 10)\n",
    "                    & (df_model.pac_to_ghost1 != True)\n",
    "                )\n",
    "                | (\n",
    "                    (df_model.status_e2 == 1)\n",
    "                    & (df_model.distance2 <= 10)\n",
    "                    & (df_model.pac_to_ghost2 != True)\n",
    "                )\n",
    "            )\n",
    "            & (df_model.status_s != 1)\n",
    "            & (df_model.status_h1 != 1)\n",
    "            & (df_model.status_h2 != 1)\n",
    "        )\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    # 只要连续的evade的index\n",
    "    evade_index = []\n",
    "    for i in consecutive_groups(tmp):\n",
    "        a = list(i)\n",
    "        if len(a) >= 3:\n",
    "            evade_index.extend(a)\n",
    "\n",
    "    hunt_index = (\n",
    "        (\n",
    "            ((df_model.status_e1 == 0) & (df_model.status_h1 == 1))\n",
    "            | ((df_model.status_e2 == 0) & (df_model.status_h2 == 1))\n",
    "        )\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "    tmp = [list(i) for i in consecutive_groups(hunt_index)]\n",
    "    planning_index = list(itertools.chain(*[i for i in tmp if len(i) <= 4]))\n",
    "\n",
    "    hunt_index1 = (\n",
    "        ((df_model.status_e1 == 0) & (df_model.status_h1 == 1))\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    hunt_index2 = (\n",
    "        ((df_model.status_e2 == 0) & (df_model.status_h2 == 1))\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    huntfailure_index = (\n",
    "        (\n",
    "            ((df_model.status_e1 == 0) & (df_model.status_h1 == 2))\n",
    "            | ((df_model.status_e2 == 0) & (df_model.status_h2 == 2))\n",
    "        )\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    graze_nohunt_index = (\n",
    "        (\n",
    "            ((df_model.status_e1 == 0) & (df_model.status_h1 == 3))\n",
    "            & ((df_model.status_e2 == 0) & (df_model.status_h2 == 3))\n",
    "        )\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "    # hunt -1 代表prehunt\n",
    "    prehunt_index = (\n",
    "        ((df_model.status_h1 == -1) | (df_model.status_h2 == -1))\n",
    "        .replace({False: np.nan})\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "    suicide_index = (\n",
    "        (df_model.status_s == 1).replace({False: np.nan}).dropna().index.tolist()\n",
    "    )\n",
    "    local_graze = list(\n",
    "        set(\n",
    "            df_model[\n",
    "                (df_model.status_g == 1) & (df_model.rwd_pac_distance_new <= 5)\n",
    "            ].index.values\n",
    "        )\n",
    "        - (\n",
    "            set(global_graze)\n",
    "            | set(hunt_index)\n",
    "            | set(prehunt_index)\n",
    "            | set(suicide_index)\n",
    "            | set(planning_index)\n",
    "        )\n",
    "    )\n",
    "    local_graze_noghost = df_model[\n",
    "        (df_model.index.isin(local_graze))\n",
    "        & (df_model.ifscared1 == 3)\n",
    "        & (df_model.ifscared2 == 3)\n",
    "    ].index\n",
    "    local_graze = list(set(local_graze) - set(local_graze_noghost))\n",
    "\n",
    "    label_dict = {\n",
    "        \"evade\": evade_index,\n",
    "        \"hunt1\": hunt_index1,\n",
    "        \"hunt2\": hunt_index2,\n",
    "        \"huntfailure_hunt\": huntfailure_index,\n",
    "        \"huntfailure_graze\": graze_nohunt_index,\n",
    "        \"prehunt\": prehunt_index,\n",
    "        \"suicide\": suicide_index,\n",
    "        \"local_graze\": local_graze,\n",
    "        \"local_graze_noghost\": local_graze_noghost,\n",
    "        \"planning\": planning_index,\n",
    "    }\n",
    "\n",
    "    for k in label_dict.keys():\n",
    "        df_model.loc[label_dict[k], \"label_\" + k] = 1\n",
    "    df_model = df_model.assign(\n",
    "        label_rest=(\n",
    "            1 - df_model.filter(regex=\"label_*\").sum(1).apply(lambda x: min(x, 1))\n",
    "        ).replace({0: np.nan})\n",
    "    )\n",
    "    return df_model\n",
    "\n",
    "df_sub = (\n",
    "    add_dis(\n",
    "        df_total.drop(columns=[\"rwd_pac_distance_new\"]).reset_index(),\n",
    "        \"pacmanPos\",\n",
    "        \"next_eat_rwd_fill\",\n",
    "        rename=\"rwd_pac_distance_new\",\n",
    "    )\n",
    "    .set_index(\"level_0\")\n",
    "    .loc[df_total.index.values]\n",
    ")\n",
    "\n",
    "df_sub = label_status(\n",
    "    df_sub.drop(\n",
    "        columns=[\n",
    "            \"label_evade\",\n",
    "            \"label_hunt1\",\n",
    "            \"label_hunt2\",\n",
    "            \"label_huntfailure_hunt\",\n",
    "            \"label_huntfailure_graze\",\n",
    "            \"label_prehunt\",\n",
    "            \"label_suicide\",\n",
    "            \"label_local_graze\",\n",
    "            \"label_local_graze_noghost\",\n",
    "            \"label_planning\",\n",
    "            \"label_rest\",\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "\"修改fruitPos的内容\"\n",
    "mask = [\n",
    "    df_sub.loc[i, \"fruitPos\"] in df_sub.loc[i, \"beans\"]\n",
    "    if not isinstance(df_sub.loc[i, \"fruitPos\"], float)\n",
    "    and not isinstance(df_sub.loc[i, \"beans\"], float)\n",
    "    else False\n",
    "    for i in range(df_sub.shape[0])\n",
    "]\n",
    "\n",
    "df_sub.fruitPos = df_sub.fruitPos.mask(~np.array(mask))\n",
    "\n",
    "\"添加label_global_ending\"\n",
    "df_sub.loc[\n",
    "    (df_sub.label_global == 1) & (df_sub.rwd_pac_distance_new <= 5),\n",
    "    \"label_global_ending\",\n",
    "] = 1\n",
    "\n",
    "df_sub.loc[\n",
    "    [\n",
    "        i[0]\n",
    "        for i in [\n",
    "            list(i)\n",
    "            for i in consecutive_groups(df_sub.label_global_ending.dropna().index)\n",
    "        ]\n",
    "        if len(i) == 1\n",
    "    ],\n",
    "    \"label_global_ending\",\n",
    "] = np.nan\n",
    "\n",
    "\"更新df_total\"\n",
    "dall[\"df_total\"] = df_sub\n",
    "\n",
    "with open(\"../constants/all_data_new.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = add_PEG_dis(df_total_small)\n",
    "\n",
    "df_total.next_pacman_dir_fill = df_total.next_pacman_dir_fill.explode()\n",
    "df_total.pacman_dir_fill = df_total.pacman_dir_fill.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有数据\n",
    "# accident：0.45，plan：0.42\n",
    "# simulation数据\n",
    "# accident：0.33，plan：0.61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plan hunting和accidentally hunting之间的区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mapping = {1: \"Accidentally Hunting\", 2: \"Planned Hunting\"}\n",
    "sns.set_palette(plt.cm.Set1.colors[:2])\n",
    "for ghost in [\"1\", \"2\"]:\n",
    "    #     for name in [\"Omega\", \"Patamon\", \"overall\"]:\n",
    "    for name in [\"simulated\"]:\n",
    "        i = 1\n",
    "        df_status = pd.DataFrame()\n",
    "        for sel_list in [cons_list_accident, cons_list_plan]:\n",
    "            if name == \"Omega\":\n",
    "                sel_list = sel_list[\n",
    "                    sel_list.explode()\n",
    "                    .reset_index()\n",
    "                    .set_index(0)\n",
    "                    .reset_index()\n",
    "                    .merge(df_total.reset_index(), left_on=0, right_on=\"level_0\")\n",
    "                    .groupby(\"index_x\")\n",
    "                    .apply(\n",
    "                        lambda x: (x.next_eat_rwd.count() - 1 / len(x) <= 0.2)\n",
    "                        & (x.level_0.values[-1] <= 686225)\n",
    "                    )\n",
    "                ]\n",
    "            elif name == \"Patamon\":\n",
    "                sel_list = sel_list[\n",
    "                    sel_list.explode()\n",
    "                    .reset_index()\n",
    "                    .set_index(0)\n",
    "                    .reset_index()\n",
    "                    .merge(df_total.reset_index(), left_on=0, right_on=\"level_0\")\n",
    "                    .groupby(\"index_x\")\n",
    "                    .apply(\n",
    "                        lambda x: (x.next_eat_rwd.count() - 1 / len(x) <= 0.2)\n",
    "                        & (x.level_0.values[0] > 686225)\n",
    "                    )\n",
    "                ]\n",
    "            else:\n",
    "                sel_list = sel_list[\n",
    "                    sel_list.explode()\n",
    "                    .reset_index()\n",
    "                    .set_index(0)\n",
    "                    .reset_index()\n",
    "                    .merge(df_total.reset_index(), left_on=0, right_on=\"level_0\")\n",
    "                    .groupby(\"index_x\")\n",
    "                    .apply(lambda x: ((x.next_eat_rwd.count() - 1) / len(x) <= 0.2))\n",
    "                ]\n",
    "            x = df_total.loc[\n",
    "                (df_total.index.isin(sel_list.apply(lambda x: x[0]).values.tolist()))\n",
    "                & (df_total.PE_dis > 10),\n",
    "                [\"PE_dis\", \"EG\" + ghost + \"_dis\"],\n",
    "            ].sum(1)\n",
    "            df_status = df_status.append(x.reset_index().assign(cate=mapping[i]))\n",
    "            print(name, mapping[i], ghost, x.mean(), x.std(), x.shape)\n",
    "            i += 1\n",
    "        plt.figure()\n",
    "        [\n",
    "            df_status[df_status.cate == i][0].hist(\n",
    "                bins=20,\n",
    "                weights=np.ones_like(df_status[df_status.cate == i][0])\n",
    "                / df_status[df_status.cate == i].shape[0],\n",
    "                alpha=0.7,\n",
    "            )\n",
    "            for i in mapping.values()\n",
    "        ]\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.legend(list(mapping.values()), title=None)\n",
    "        plt.xlabel(\"PacMan-Energizer distance + Energizer-Ghost\" + ghost + \" distance\")\n",
    "        plt.ylabel(\"probability\")\n",
    "        plt.title(name)\n",
    "        plt.savefig(\n",
    "            \"../\" + name.lower() + \"pics/4A\" + ghost + \"_ghost.pdf\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### suicide heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnt = (\n",
    "    df_total.loc[:, [\"game\", \"game_trial\"]]\n",
    "    .drop_duplicates()\n",
    "    .merge(\n",
    "        df_total.groupby(\"game\")[\"game_trial\"].max().reset_index(),\n",
    "        on=\"game\",\n",
    "        suffixes=[\"_curr_trial\", \"_total_trial\"],\n",
    "    )\n",
    ").pivot_table(\n",
    "    columns=\"game_trial_curr_trial\", index=\"game_trial_total_trial\", aggfunc=\"count\"\n",
    ")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    (\n",
    "        (\n",
    "            df_total.loc[df_total.label_suicide == 1, [\"game\", \"game_trial\"]]\n",
    "            .drop_duplicates()\n",
    "            .merge(\n",
    "                df_total.groupby(\"game\")[\"game_trial\"].max().reset_index(),\n",
    "                on=\"game\",\n",
    "                suffixes=[\"_curr_trial\", \"_total_trial\"],\n",
    "            )\n",
    "        ).pivot_table(\n",
    "            columns=\"game_trial_curr_trial\",\n",
    "            index=\"game_trial_total_trial\",\n",
    "            aggfunc=\"count\",\n",
    "        )\n",
    "        / base_cnt\n",
    "    ).dropna(axis=1, how=\"all\"),\n",
    "    cmap=\"binary\",\n",
    "    vmin=0.45,\n",
    ")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图1B, 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape = True\n",
    "exclude_2dirs = False\n",
    "only_cross_fork = False  # 去掉直线的运动方向，是不是向左和向右的比例一致\n",
    "# two_sides_diff = False  # 只要算左边和右边豆子的区别\n",
    "\n",
    "name = \"simulated\"\n",
    "\"\"\"把每个点周围四个方向的豆子数算出来，然后算出1)最大的方向 2)最大的两个方向的豆子的差距 3)添加NextNum 4)pacman的位置\"\"\"\n",
    "\n",
    "landscape_colors = {\n",
    "    \"straight\": \"firebrick\",\n",
    "    \"L-shape\": \"MediumBlue\",\n",
    "    \"fork\": \"darkgreen\",\n",
    "    \"cross\": \"Khaki\",\n",
    "}\n",
    "\n",
    "df_sub = df_total_small[df_total_small.status == \"local_record\"]\n",
    "for land in landscape_colors.keys():\n",
    "    set_landcolor(landscape_colors, landscape)\n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    ## 如果是全部的数据，要换下面这个function\n",
    "    df_overlap = extend_df_overlap(\n",
    "        df_sub,\n",
    "        (\n",
    "            (df_sub[[\"distance1\", \"distance2\"]].min(1) >= 3)\n",
    "            & ((df_sub.ifscared1 >= 4) | (df_sub.ifscared2 >= 4))\n",
    "        ).tolist(),\n",
    "        \"simulated\",\n",
    "    )\n",
    "    go_to_most_beans(\n",
    "        df_overlap,\n",
    "        cate_df,\n",
    "        \"../\" + name + \"pics/1D2_over3.pdf\",\n",
    "        only_cross_fork,\n",
    "        exclude_2dirs,\n",
    "        landscape,\n",
    "    )\n",
    "    if landscape:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1C(df_sub, name):\n",
    "    df_sub = add_possible_dirs(df_sub)\n",
    "    rs = toward_ghost_table(df_sub)\n",
    "    dd = {\n",
    "        \"ghost(red) normal\": {\"color\": \"firebrick\", \"linestyle\": \"-\"},\n",
    "        \"ghost(red) scared\": {\"color\": \"SlateBlue\", \"linestyle\": \"-\",},\n",
    "        \"ghost(yellow) normal\": {\"color\": \"khaki\", \"linestyle\": \"-\"},\n",
    "        \"ghost(yellow) scared\": {\"color\": \"Aquamarine\", \"linestyle\": \"-\",},\n",
    "    }\n",
    "    # sns.set_palette(plt.cm.Set1.colors[:2][::-1])\n",
    "    # key = \"2\"\n",
    "    # ghost_color = mapping_d[key]\n",
    "    f = plt.figure()\n",
    "    for idx, gpd in rs.groupby([\"ifscared1\"]):\n",
    "        plt.errorbar(\n",
    "            gpd[\"level_0\"],\n",
    "            gpd[\"mean\"],\n",
    "            yerr=gpd[\"std\"] / np.sqrt(gpd[\"count\"]),\n",
    "            marker=None,\n",
    "            capsize=3,\n",
    "            barsabove=True,\n",
    "            label=idx,\n",
    "            **dd[idx],\n",
    "        )\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"pacman - ghost distance\")\n",
    "    plt.ylabel(\"% of toward ghost\")\n",
    "    plt.title(\"pacman's move diminishes manhat. distance of pacman-ghost\",)\n",
    "\n",
    "    plt.ylim(0, 1)\n",
    "    f.savefig(\"../\" + name + \"pics/1C_test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_1C(df_sub, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2B(df_total, global_handler_sec):\n",
    "    df_com = pd.DataFrame()\n",
    "    for n in [0, -2]:\n",
    "        initial_index = [i[n] for i in global_handler_sec]\n",
    "        df_temp = (\n",
    "            add_dis(df_total.loc[initial_index].explode(\"beans\"), \"beans\", \"pacmanPos\")\n",
    "            .groupby([\"file\", \"index\"])\n",
    "            .apply(lambda x: x[x.dis <= 5].shape[0])\n",
    "        )\n",
    "        df_com = pd.concat([df_com, df_temp.reset_index()], 1)\n",
    "\n",
    "    df_com.columns = [\"file\", \"index\", \"start\", \"file\", \"index\", \"end\"]\n",
    "\n",
    "    df_com = pd.concat(\n",
    "        [\n",
    "            df_com.end.apply(lambda x: int(min(x, 8))).value_counts(normalize=True),\n",
    "            df_com.start.apply(lambda x: int(min(x, 8))).value_counts(normalize=True),\n",
    "            (df_com.end - df_com.start)\n",
    "            .apply(lambda x: int(min(x, 8)))\n",
    "            .value_counts(normalize=True)\n",
    "            .rename(\"end - start\"),\n",
    "        ],\n",
    "        1,\n",
    "    )\n",
    "    sns.set_palette(\"Set1\")\n",
    "    ax = df_com.loc[0:].plot(kind=\"bar\")\n",
    "    ax.set_title(\"bean count at global graze start and end point\")\n",
    "    ax.set_xlabel(\"# of surrounding beans\")\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "    ax.set_ylabel(\"normalized trial count\")\n",
    "    ax.figure.savefig(\"../overallpics/2B.pdf\")\n",
    "\n",
    "plot_2B(df_total, global_handler_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2C(df_total, global_handler):\n",
    "    df_total.loc[\n",
    "        ~df_total.assign(beansshift=df_total.beans.shift()).apply(\n",
    "            lambda x: x.next_eat_rwd in x.beansshift\n",
    "            if not isinstance(x.beansshift, float)\n",
    "            else False,\n",
    "            1,\n",
    "        ),\n",
    "        \"next_eat_rwd\",\n",
    "    ] = np.nan  # 去掉被吃掉的鬼\n",
    "\n",
    "    df_result = df_total.groupby(\"file\").apply(if_get_nearbean).reset_index()\n",
    "    df_result.ifeatnear = df_result.ifeatnear.astype(int)\n",
    "    df_result = df_result[df_result.start_index.isin(global_handler)]\n",
    "\n",
    "    df_plot = (\n",
    "        df_result[df_result.level_1 > 0]\n",
    "        .groupby(\n",
    "            ((df_result[df_result.level_1 > 0].rwd_cnt) / 5)\n",
    "            .map(np.ceil)\n",
    "            .apply(lambda x: min(8, x))\n",
    "        )\n",
    "        .ifeatnear.agg([\"mean\", \"std\", \"count\"])\n",
    "        .assign(rwd_cnt_actual=np.linspace(5, 40, 8))\n",
    "    )\n",
    "\n",
    "    sns.set_palette(\"tab20b\")\n",
    "    ax = sns.scatterplot(\n",
    "        size=\"count\", data=df_plot, x=\"rwd_cnt_actual\", y=\"mean\", sizes=(20, 100),\n",
    "    )\n",
    "    plt.errorbar(\n",
    "        data=df_plot,\n",
    "        x=\"rwd_cnt_actual\",\n",
    "        y=\"mean\",\n",
    "        yerr=df_plot[\"std\"] / np.sqrt(df_plot[\"count\"]),\n",
    "        capsize=3,\n",
    "    )\n",
    "    ax.set_xticks(np.linspace(5, 40, 8))\n",
    "    ax.set_xticklabels(list(np.linspace(5, 40, 8).astype(int))[:-1] + [\">=40\"])\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.xlabel(\"# of remaining beans\")\n",
    "    plt.ylabel(\"% of eating the closet bean\")\n",
    "    plt.savefig(\"../overallpics/2C.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2C(df_total, global_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_total[(df_total.status == \"global_record\")]\n",
    "\n",
    "actual_shortest = df_sub.groupby(\"trialid\").apply(\n",
    "    lambda x: pd.Series(\n",
    "        [\n",
    "            x[~x.next_eat_rwd.isnull()].index.values[0],\n",
    "            x.iloc[:2][\"pacmanPos\"].drop_duplicates(keep=\"last\").index.values[0],\n",
    "            LOCS_DF[\n",
    "                (LOCS_DF.pos1 == x.pacmanPos.values[0])\n",
    "                & (LOCS_DF.pos2 == x.next_eat_rwd.dropna().values[0])\n",
    "            ].dis.values[0],\n",
    "            (x.pacman_dir_fill.iloc[1:] != x.pacman_dir_fill.iloc[1:].shift())\n",
    "            .loc[\n",
    "                x.iloc[:2][\"pacmanPos\"]\n",
    "                .drop_duplicates(keep=\"last\")\n",
    "                .index.values[0] : x[~x.next_eat_rwd.isnull()]\n",
    "                .index.values[0]\n",
    "            ]\n",
    "            .sum()\n",
    "            - 1,\n",
    "            count_change_dir(\n",
    "                LOCS_DF[\n",
    "                    (LOCS_DF.pos1 == x.pacmanPos.values[0])\n",
    "                    & (LOCS_DF.pos2 == x.next_eat_rwd.dropna().values[0])\n",
    "                ].path.values[0]\n",
    "            ),\n",
    "        ],\n",
    "        index=[\"curr_index\", \"prev_index\", \"dis\", \"actual_crosses\", \"shortest_crosses\"],\n",
    "    )\n",
    "    if x[~x.next_eat_rwd.isnull()].shape[0] > 0\n",
    "    else pd.Series(\n",
    "        [np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "        index=[\"curr_index\", \"prev_index\", \"dis\", \"actual_crosses\", \"shortest_crosses\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D(actual_shortest, name=\"overall\"):\n",
    "    ylim = 10\n",
    "    plt.subplots()\n",
    "    df_plot = actual_shortest[actual_shortest.dis >= 10]\n",
    "    data = (\n",
    "        (df_plot.curr_index - df_plot.prev_index - df_plot.dis)\n",
    "        .where(lambda x: (x <= 10) & (x >= 0))\n",
    "        .dropna()\n",
    "        .value_counts()\n",
    "        .sort_index()\n",
    "        .reset_index()\n",
    "    )\n",
    "    ax = sns.barplot(\n",
    "        data=data, x=\"index\", y=data[0] / data[0].sum(), palette=\"Blues_r\",\n",
    "    )\n",
    "    ax.set_xticks(range(ylim + 1))\n",
    "    ax.set_xticklabels(range(ylim + 1))\n",
    "    ax.set_xlabel(\"actual trajectory length-shortest trajectory length\")\n",
    "    ax.set_ylabel(\"normalized trial count\")\n",
    "    ax.figure.savefig(\"../\" + name + \"pics/2D-1.pdf\")\n",
    "\n",
    "    plt.subplots()\n",
    "    data = (\n",
    "        (df_plot.actual_crosses - df_plot.shortest_crosses)\n",
    "        .where(lambda x: x >= 0)\n",
    "        .dropna()\n",
    "        .apply(lambda x: int(min(x, 5)))\n",
    "        .value_counts()\n",
    "        .sort_index()\n",
    "        .reset_index()\n",
    "    )\n",
    "    ax = sns.barplot(data=data, x=\"index\", y=data[0] / data[0].sum(), palette=\"Blues_r\")\n",
    "    ax.set_xticks(range(6))\n",
    "    ax.set_xticklabels(list(range(5)) + [\">=5\"])\n",
    "    ax.set_xlabel(\"actual trajectory turns-fewest trajectory turns\")\n",
    "    ax.set_ylabel(\"normalized trial count\")\n",
    "    ax.figure.savefig(\"../\" + name + \"pics/2D-2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D(actual_shortest, name=\"simulated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2E(actual_shortest, name=\"overall\"):\n",
    "    sns.set_palette(\"tab20b\")\n",
    "    plot_data = actual_shortest[actual_shortest.dis >= 10]\n",
    "    for i in [1, 2]:\n",
    "        plt.subplots()\n",
    "        if i == 1:\n",
    "            df_plot = plot_data.groupby(\n",
    "                plot_data.dis.apply(lambda x: min(x, 35))\n",
    "            ).apply(\n",
    "                lambda x: pd.Series(\n",
    "                    {\n",
    "                        \"avg\": (x.curr_index - x.prev_index - x.dis).mean(),\n",
    "                        \"std\": (x.curr_index - x.prev_index - x.dis).std()\n",
    "                        / np.sqrt(x.shape[0]),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            df_plot = plot_data.groupby(\n",
    "                plot_data.dis.apply(lambda x: min(x, 35))\n",
    "            ).apply(\n",
    "                lambda x: pd.Series(\n",
    "                    {\n",
    "                        \"avg\": (x.actual_crosses - x.shortest_crosses).mean(),\n",
    "                        \"std\": (x.actual_crosses - x.shortest_crosses).std()\n",
    "                        / np.sqrt(x.shape[0]),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        plt.errorbar(\n",
    "            y=df_plot[\"avg\"],\n",
    "            x=df_plot.index,\n",
    "            yerr=df_plot[\"std\"],\n",
    "            marker=None,\n",
    "            capsize=3,\n",
    "            barsabove=True,\n",
    "        )\n",
    "        # ax.invert_yaxis()\n",
    "        b, t = plt.ylim()  # discover the values for bottom and top\n",
    "        plt.ylim(b - 0.5, t + 0.5)  # update the ylim(bottom, top) values\n",
    "        if i == 1:\n",
    "            plt.ylabel(\"actual length - dijkstra distance\")\n",
    "        else:\n",
    "            plt.ylabel(\"actual trajectory turns - fewest trajectory turns\")\n",
    "        plt.xlabel(\"dijkstra distance\")\n",
    "        plt.xticks(\n",
    "            ticks=range(10, 40, 5), labels=list(range(10, 35, 5)) + [\">= 35\"],\n",
    "        )\n",
    "        plt.savefig(\"../\" + name + \"pics/2E-\" + str(i) + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2E(actual_shortest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3B5C(df_total, states, prefix):\n",
    "    sns.set_palette(\n",
    "        [\n",
    "            \"green\",\n",
    "            \"firebrick\",\n",
    "            \"khaki\",\n",
    "            \"PaleTurquoise\",\n",
    "            \"red\",\n",
    "            \"orange\",\n",
    "            \"pink\",\n",
    "            \"grey\",\n",
    "        ]\n",
    "    )\n",
    "    for state in states:\n",
    "        fig, ax = plt.subplots(dpi=300)\n",
    "        if state == \"hunt\":\n",
    "            sel_df = df_total[(df_total.label_hunt2 == 1) | (df_total.label_hunt1 == 1)]\n",
    "        elif state == \"global graze\":\n",
    "            sel_df = df_total[df_total.label_global_optimal == 1]\n",
    "        elif state == \"local graze in scared mode\":\n",
    "            sel_df = df_total[\n",
    "                (df_total.label_local_graze == 1)\n",
    "                & ((df_total.ifscared1 >= 4) | (df_total.ifscared2 >= 4))\n",
    "            ]\n",
    "        elif state == \"evade\":\n",
    "            sel_df = df_total[df_total.label_evade == 1]\n",
    "        elif state == \"suicide\":\n",
    "            sel_df = df_total[df_total.label_suicide == 1]\n",
    "        else:\n",
    "            sel_df = df_total[\n",
    "                (df_total.lap'lbel_local_graze == 1)\n",
    "                & ((df_total.ifscared1 <= 2) & (df_total.ifscared2 <= 2))\n",
    "            ]\n",
    "        pd.DataFrame(\n",
    "            sel_df[\n",
    "                [\n",
    "                    \"pacman_sacc\",\n",
    "                    \"ghost1Pos_sacc\",\n",
    "                    \"ghost2Pos_sacc\",\n",
    "                    \"beans_sacc\",\n",
    "                    \"energizer_sacc\",\n",
    "                    \"for_sacc\",\n",
    "                    \"back_sacc\",\n",
    "                    \"wandering\",\n",
    "                ]\n",
    "            ]\n",
    "            .fillna(False)\n",
    "            .mean()\n",
    "        ).T.plot(kind=\"bar\", ax=ax)\n",
    "        ax.set_xticklabels([\"\"], rotation=0)\n",
    "        ax.set_ylabel(\"saccade ratio\")\n",
    "        plt.legend(\n",
    "            [\n",
    "                \"pacman\",\n",
    "                \"ghost1\",\n",
    "                \"ghost2\",\n",
    "                \"beans\",\n",
    "                \"energizer\",\n",
    "                \"forward\",\n",
    "                \"backward\",\n",
    "                \"wandering\",\n",
    "            ],\n",
    "            ncol=2, loc='upper left'\n",
    "        )\n",
    "        plt.ylim(0, 0.6)\n",
    "        plt.title(state)\n",
    "        plt.savefig(\"../overallpics/\" + prefix + state + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_3B5C(df_total, [\n",
    "        \"hunt\",\n",
    "        \"global graze\",\n",
    "        \"local graze in scared mode\",\n",
    "        \"local graze in normal mode\",\n",
    "],'3B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3C(df_total, name=\"overall\"):\n",
    "    sns.set_palette(\n",
    "        [\n",
    "            \"green\",\n",
    "            \"firebrick\",\n",
    "            #      \"khaki\",\n",
    "            \"orange\",\n",
    "            #      \"pink\",\n",
    "            #      \"red\",\n",
    "            \"PaleTurquoise\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    upper = 18\n",
    "    interval = 2\n",
    "    state_name = {\n",
    "        \"hunt\": \"hunt\",\n",
    "        \"global graze\": \"global\",\n",
    "        \"local graze in scared mode\": \"local_scared\",\n",
    "        \"local graze in normal mode\": \"local_normal\",\n",
    "    }\n",
    "    for state in state_name.keys():\n",
    "        fig, ax = plt.subplots(figsize=(7, 4))\n",
    "        if state == \"hunt\":\n",
    "            sel_index = [\n",
    "                list(i)\n",
    "                for i in consecutive_groups(\n",
    "                    df_total[\n",
    "                        (df_total.label_hunt2 == 1) | (df_total.label_hunt1 == 1)\n",
    "                    ].index\n",
    "                )\n",
    "            ]\n",
    "        elif state == \"global graze\":\n",
    "            sel_index = [\n",
    "                list(i)\n",
    "                for i in consecutive_groups(\n",
    "                    df_total[(df_total.label_global == 1)].index\n",
    "                )\n",
    "            ]\n",
    "        elif state == \"local graze in scared mode\":\n",
    "            sel_index = [\n",
    "                list(i)\n",
    "                for i in consecutive_groups(\n",
    "                    df_total[\n",
    "                        (df_total.label_local_graze == 1)\n",
    "                        & ((df_total.ifscared1 >= 4) | (df_total.ifscared2 >= 4))\n",
    "                    ].index\n",
    "                )\n",
    "            ]\n",
    "        else:\n",
    "            sel_index = [\n",
    "                list(i)\n",
    "                for i in consecutive_groups(\n",
    "                    df_total[\n",
    "                        (df_total.label_local_graze == 1)\n",
    "                        & ((df_total.ifscared1 <= 2) & (df_total.ifscared2 <= 2))\n",
    "                    ].index\n",
    "                )\n",
    "            ]\n",
    "        for w in [\n",
    "            \"pacman_sacc\",\n",
    "            \"ghost\",\n",
    "            \"for_sacc\",\n",
    "            \"beans_sacc\",\n",
    "        ]:\n",
    "            if w == \"ghost\":\n",
    "                tmp = [\n",
    "                    len(i)\n",
    "                    * 25\n",
    "                    / 60\n",
    "                    / df_total.loc[i, [\"ghost1Pos_sacc\", \"ghost2Pos_sacc\"]].sum(1).sum()\n",
    "                    for i in sel_index\n",
    "                    if df_total.loc[i, [\"ghost1Pos_sacc\", \"ghost2Pos_sacc\"]]\n",
    "                    .sum(1)\n",
    "                    .sum()\n",
    "                    > 0\n",
    "                ]\n",
    "            else:\n",
    "                tmp = [\n",
    "                    len(i) * 25 / 60 / df_total.loc[i, w].sum()\n",
    "                    for i in sel_index\n",
    "                    if df_total.loc[i, w].sum() > 0\n",
    "                ]\n",
    "            tmp = list(filter(lambda x: x <= upper, tmp))\n",
    "            ax.plot(\n",
    "                (\n",
    "                    (\n",
    "                        pd.cut(\n",
    "                            pd.Series(tmp).apply(lambda x: min(x, upper)),\n",
    "                            range(0, upper + interval, interval),\n",
    "                            labels=list(range(interval, upper + interval, interval)),\n",
    "                        ).value_counts()\n",
    "                    ).sort_index()\n",
    "                    / len(tmp)\n",
    "                ),\n",
    "                marker=\"o\",\n",
    "            )\n",
    "        plt.legend(\n",
    "            [\n",
    "                \"pacman_sacc\",\n",
    "                \"ghost_sacc\",\n",
    "                \"for_sacc\",\n",
    "                #             \"back_sacc\",\n",
    "                #             \"energizer_sacc\",\n",
    "                \"beans_sacc\",\n",
    "            ],\n",
    "            ncol=2,\n",
    "        )\n",
    "        ax.set_xticks(range(int(upper / interval)))\n",
    "        ax.set_xticklabels(\n",
    "            list(range(interval, upper + interval, interval))[:-1] + [\">=\" + str(upper)]\n",
    "        )\n",
    "        plt.xlabel(\"Average Saccade Seconds Interval (bins = \" + str(interval) + \")\")\n",
    "        plt.ylabel(\"Nomarlized Trial Count\")\n",
    "        plt.title(state)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.savefig(\"../\" + name + \"pics/3C_\" + state_name[state] + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_3C(df_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rt(which_monkey):\n",
    "    pixel_dfs = pd.read_pickle(\n",
    "        \"../constants/pixel_dfs_\" + which_monkey.lower() + \".pkl\"\n",
    "    )\n",
    "    rt = (\n",
    "        pd.read_pickle(\"../constants/rt_with_norm_\" + which_monkey.lower() + \".pkl\")\n",
    "        .rename(columns={\"pacmanPos_x\": \"pacmanPos\"})\n",
    "        .reset_index()\n",
    "        .merge(\n",
    "            pixel_dfs.pacmanPos.reset_index().rename(\n",
    "                columns={\"index\": \"level_0_y\", \"pacmanPos\": \"first_pos\"}\n",
    "            ),\n",
    "            on=\"level_0_y\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .set_index(\"level_0_x\")\n",
    "    )\n",
    "\n",
    "    rt = assign_category(rt)\n",
    "    rt = pd.concat(\n",
    "        [\n",
    "            rt,\n",
    "            rt[[\"file\", \"index\"]]\n",
    "            .assign(\n",
    "                merge_key=rt.apply(\n",
    "                    lambda x: list(\n",
    "                        range(max(int(x[\"index\"]) - 20, 0), int(x[\"index\"]) - 1)\n",
    "                    ),\n",
    "                    1,\n",
    "                )\n",
    "            )\n",
    "            .explode(\"merge_key\")\n",
    "            .reset_index()\n",
    "            .merge(\n",
    "                rt[[\"file\", \"index\"]],\n",
    "                left_on=[\"file\", \"merge_key\"],\n",
    "                right_on=[\"file\", \"index\"],\n",
    "            )\n",
    "            .groupby(\"level_0_x\")\n",
    "            .size()\n",
    "            .rename(\"turns_previous\"),\n",
    "        ],\n",
    "        1,\n",
    "    )\n",
    "\n",
    "    rt[\"previous_steps\"] = rt[\"index\"].diff()  # 这个是进入s弯step之前走的路程\n",
    "    return rt\n",
    "\n",
    "\n",
    "# rt = read_rt(\"omega\").append(read_rt(\"patamon\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3D(rt, area, name_num, conda, condb, name=\"overall\"):\n",
    "    global state_color\n",
    "    plt.subplots()\n",
    "    value_col = \"rt_std\"\n",
    "    target_col = \"next_eat_rwd_fill\"\n",
    "    tags = [\"local graze in normal mode\", \"global graze\"]\n",
    "    cnt = 0\n",
    "    stats = add_dis(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [\n",
    "                    df_total.loc[i[0], \"pacmanPos\"],\n",
    "                    df_total.loc[i[-1], \"pacmanPos\"],\n",
    "                    len(i) - 1,\n",
    "                ]\n",
    "                for i in global_handler_sec\n",
    "            ],\n",
    "            columns=[\"startPos\", \"endPos\", \"length\"],\n",
    "        ),\n",
    "        \"startPos\",\n",
    "        \"endPos\",\n",
    "    )\n",
    "\n",
    "    df_rt_local_normal = df_total[\n",
    "        (df_total.label_local_graze == 1)\n",
    "        & (df_total.ifscared1 <= 2)\n",
    "        & (df_total.ifscared2 <= 2)\n",
    "    ][[\"file\", \"index\"]]\n",
    "\n",
    "    df_rt_global = df_total[\n",
    "        (df_total.label_global_optimal == 1)\n",
    "        & (\n",
    "            df_total.index.isin(\n",
    "                list(\n",
    "                    itertools.chain(\n",
    "                        *pd.Series(global_handler_sec)[(stats.length >= 10)].apply(\n",
    "                            lambda x: x[:-5]\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ][[\"file\", \"index\"]]\n",
    "\n",
    "    for tag in tags:\n",
    "        df_ = add_dis(\n",
    "            rt.loc[\n",
    "                (rt.category != \"fork-side\")\n",
    "                & (rt.pacmanPos.isin(area))\n",
    "                & (rt.first_pos.isin(TURNING_POS)),\n",
    "                [\n",
    "                    \"file\",\n",
    "                    \"index\",\n",
    "                    value_col,\n",
    "                    \"pacmanPos\",\n",
    "                    \"pacman_dir\",\n",
    "                    \"level_0_y\",\n",
    "                    \"first_pos\",\n",
    "                ],\n",
    "            ],\n",
    "            \"first_pos\",\n",
    "            \"pacmanPos\",\n",
    "        )\n",
    "        if tag == \"local graze in scared mode\":\n",
    "            df_plot = add_dis(\n",
    "                df_.merge(\n",
    "                    df_total[\n",
    "                        (df_total.label_local_graze == 1)\n",
    "                        & ((df_total.ifscared1 >= 4) | (df_total.ifscared2 >= 4))\n",
    "                    ][[\"file\", \"index\", target_col]],\n",
    "                    on=[\"file\", \"index\"],\n",
    "                ).drop(columns=\"dis\"),\n",
    "                \"pacmanPos\",\n",
    "                target_col,\n",
    "            )\n",
    "        elif tag == \"local graze in normal mode\":\n",
    "            df_plot = add_dis(\n",
    "                df_.merge(\n",
    "                    df_total.loc[\n",
    "                        df_rt_local_normal.index, [\"file\", \"index\", target_col]\n",
    "                    ],\n",
    "                    on=[\"file\", \"index\"],\n",
    "                ).drop(columns=\"dis\"),\n",
    "                \"pacmanPos\",\n",
    "                target_col,\n",
    "            )\n",
    "        elif tag == \"global graze\":\n",
    "            df_plot = add_dis(\n",
    "                df_.merge(\n",
    "                    df_total.loc[df_rt_global.index, [\"file\", \"index\", target_col]],\n",
    "                    on=[\"file\", \"index\"],\n",
    "                ).drop(columns=\"dis\"),\n",
    "                \"pacmanPos\",\n",
    "                target_col,\n",
    "            )\n",
    "        elif tag == \"hunt\":\n",
    "            df_plot = add_dis(\n",
    "                df_.merge(\n",
    "                    df_total[(df_total.label_hunt1 == 1) | (df_total.label_hunt2 == 1)][\n",
    "                        [\"file\", \"index\", target_col]\n",
    "                    ],\n",
    "                    on=[\"file\", \"index\"],\n",
    "                ).drop(columns=\"dis\"),\n",
    "                \"pacmanPos\",\n",
    "                target_col,\n",
    "            )\n",
    "        elif tag == \"evade\":\n",
    "            df_plot = add_dis(\n",
    "                df_.merge(\n",
    "                    df_total[(df_total.label_evade == 1)][\n",
    "                        [\"file\", \"index\", target_col]\n",
    "                    ],\n",
    "                    on=[\"file\", \"index\"],\n",
    "                ).drop(columns=\"dis\"),\n",
    "                \"pacmanPos\",\n",
    "                target_col,\n",
    "            )\n",
    "        elif tag == \"suicide\":\n",
    "            df_plot = add_dis(\n",
    "                df_.merge(\n",
    "                    df_total[(df_total.label_suicide == 1)][\n",
    "                        [\"file\", \"index\", target_col]\n",
    "                    ],\n",
    "                    on=[\"file\", \"index\"],\n",
    "                ).drop(columns=\"dis\"),\n",
    "                \"pacmanPos\",\n",
    "                target_col,\n",
    "            )\n",
    "        elif tag == \"accidentally hunt\":\n",
    "            df_plot = add_dis(\n",
    "                df_.merge(\n",
    "                    df_total.loc[\n",
    "                        df_total.index.isin(list(itertools.chain(*cons_list_accident)))\n",
    "                    ][[\"file\", \"index\", target_col]],\n",
    "                    on=[\"file\", \"index\"],\n",
    "                ).drop(columns=\"dis\"),\n",
    "                \"pacmanPos\",\n",
    "                target_col,\n",
    "            )\n",
    "        elif tag == \"planning hunt\":\n",
    "            df_plot = add_dis(\n",
    "                df_.merge(\n",
    "                    df_total.loc[\n",
    "                        df_total.index.isin(list(itertools.chain(*cons_list_plan)))\n",
    "                    ][[\"file\", \"index\", target_col]],\n",
    "                    on=[\"file\", \"index\"],\n",
    "                ).drop(columns=\"dis\"),\n",
    "                \"pacmanPos\",\n",
    "                target_col,\n",
    "            )\n",
    "        if value_col == \"rt_std\":\n",
    "            df_plot = df_plot[df_plot.dis.fillna(0).between(conda, condb)][value_col]\n",
    "            df_plot.hist(\n",
    "                bins=np.linspace(-1.5, 1.5, 31),\n",
    "                weights=np.ones_like(df_plot) / df_plot.shape[0],\n",
    "                alpha=0.7,\n",
    "                color=state_color[tag],\n",
    "            )\n",
    "            add_stats(df_plot, color=state_color[tag], x=-1.5, y=0.13 - cnt * 0.1)\n",
    "        else:\n",
    "            df_plot = (\n",
    "                df_plot[df_plot.dis.fillna(0).between(conda, condb)][value_col] / 60\n",
    "            )\n",
    "            df_plot.hist(\n",
    "                bins=np.linspace(-1.5, 3, 46),\n",
    "                weights=np.ones_like(df_plot) / df_plot.shape[0],\n",
    "                alpha=0.7,\n",
    "                color=state_color[tag],\n",
    "            )\n",
    "            add_stats(df_plot, color=state_color[tag], x=-1.5, y=0.18 - cnt * 0.1)\n",
    "        cnt += 1\n",
    "    plt.ylim(0, 0.25)\n",
    "    plt.grid(False)\n",
    "    plt.legend(tags)\n",
    "    plt.xlabel(\"RT in seconds\")\n",
    "    plt.ylabel(\"normalized count\")\n",
    "    # plt.title(value_col)\n",
    "    plt.savefig(\"../\" + name + \"pics/\" + name_num + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3D(rt[rt.file.str.contains(\"Patamon\")], red_pos, \"3D1\", -1, np.inf, \"patamon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图4A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_4A(df_total, cons_list_accident, cons_list_plan, name=\"overall\"):\n",
    "    name_map = {\"1\": \"Blinky\", \"2\": \"Clyde\"}\n",
    "    end = 3\n",
    "    for w in [\"1\", \"2\"]:\n",
    "        bins = range(0, 50, 5)\n",
    "        f = plt.figure(figsize=(8, 5))\n",
    "        bb = pd.concat(\n",
    "            [\n",
    "                (\n",
    "                    pd.value_counts(\n",
    "                        pd.cut(\n",
    "                            [\n",
    "                                df_total.loc[i[:end], \"distance\" + w].mean()\n",
    "                                for i in cons_list_plan\n",
    "                            ],\n",
    "                            bins,\n",
    "                            labels=range(5, 50, 5),\n",
    "                        ),\n",
    "                        normalize=True,\n",
    "                    )\n",
    "                    .rename(\"distance\")\n",
    "                    .reset_index()\n",
    "                    .assign(category=\"Planned Attack\")\n",
    "                ),\n",
    "                (\n",
    "                    pd.value_counts(\n",
    "                        pd.cut(\n",
    "                            [\n",
    "                                df_total.loc[i[:end], \"distance\" + w].mean()\n",
    "                                for i in cons_list_accident\n",
    "                            ],\n",
    "                            bins,\n",
    "                            labels=range(5, 50, 5),\n",
    "                        ),\n",
    "                        normalize=True,\n",
    "                    )\n",
    "                    .rename(\"distance\")\n",
    "                    .reset_index()\n",
    "                    .assign(category=\"Accidental Attack\")\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        sns.set_palette(plt.cm.Set1.colors[:2][::-1])\n",
    "        sns.barplot(data=bb, x=\"index\", y=\"distance\", hue=\"category\")\n",
    "\n",
    "        plt.legend(title=None)\n",
    "        plt.xlabel(\"PacMan-Ghost Distance\")\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.ylim(0, 0.4)\n",
    "        plt.title(\"Ghost \" + name_map[w])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"../\" + name + \"pics/4Aghost\" + w + \".pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_4A(\n",
    "    df_total[df_total.file.str.contains(\"-\")],\n",
    "    cons_list_accident.apply(lambda x: x if x[0] >= -1 else np.nan).dropna().values,\n",
    "    cons_list_plan.apply(lambda x: x if x[0] >= -1 else np.nan).dropna().values,\n",
    ")\n",
    "# from scipy.stats import ttest_ind, ks_2samp\n",
    "\n",
    "# ks_2samp(\n",
    "#     [df_total.loc[i[:3], \"distance2\"].mean() for i in cons_list_accident],\n",
    "#     [df_total.loc[i[:3], \"distance2\"].mean() for i in cons_list_plan],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图4B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_4B1(df_total, map_indexes_accident, name=\"overall\"):\n",
    "    df = add_combine_huntdis(df_total, map_indexes_accident)\n",
    "    \"\"\"比例\"\"\"\n",
    "    bincut = 2\n",
    "    df_plot = df[\n",
    "        (df[\"rwd_pac_distance\"] > 0) & (df.status_h1 <= 1) & (df.status_h2 <= 1)\n",
    "    ].pivot_table(\n",
    "        columns=np.ceil(df[\"rwd_pac_distance\"] / bincut) * bincut,\n",
    "        index=np.ceil(df[\"combine_dis\"] / bincut) * bincut,\n",
    "        values=\"combine_hunt\",\n",
    "        aggfunc=lambda x: sum(x == 1) / len(x) if len(x) > 3 else np.nan,\n",
    "    )\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = sns.heatmap(\n",
    "        df_plot.reindex(range(0, 46, 2)).T.reindex(range(0, 26, 2)).T,\n",
    "        square=True,\n",
    "        cmap=\"coolwarm\",\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cbar_kws={\"shrink\": 0.7},\n",
    "    )\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticklabels(\n",
    "        [i.get_text().split(\".\")[0] for i in ax.get_xticklabels()], rotation=0\n",
    "    )\n",
    "    ax.set_yticklabels([i.get_text().split(\".\")[0] for i in ax.get_yticklabels()])\n",
    "    ax.set_ylabel(\"P-G Distance\")\n",
    "    ax.set_xlabel(\"P-Nearest B Distance\")\n",
    "    b, t = plt.ylim()  # discover the values for bottom and top\n",
    "    plt.ylim(b - 0.5, t + 0.5)  # update the ylim(bottom, top) values\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_ticks([0, 1])\n",
    "    cbar.set_ticklabels([0, 1])\n",
    "    ax.figure.savefig(\"../\" + name + \"pics/4B1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_4B1(\n",
    "    df_total,\n",
    "    pd.Series(\n",
    "        [\n",
    "            list(i)\n",
    "            for i in consecutive_groups(\n",
    "                df_total[\n",
    "                    (df_total.status == \"local_record\") & (df_total.ifscared1 > 3)\n",
    "                ].index\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    \"simulated\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图4B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_4B2(df_total, map_indexes_plan, name=\"overall\"):\n",
    "    df = df_total.loc[list(itertools.chain(*map_indexes_plan))]\n",
    "\n",
    "    \"\"\"结合鬼1和鬼2的hunt\"\"\"\n",
    "    df[\"combine_hunt\"] = (\n",
    "        df[[\"label_hunt1\", \"label_hunt2\"]].sum(1).apply(lambda x: min(x, 1))\n",
    "    )\n",
    "\n",
    "    df.loc[(df.label_hunt1.isnull()) & (df.label_hunt2 == 1), \"combine_dis\"] = df.loc[\n",
    "        (df.label_hunt1.isnull()) & (df.label_hunt2 == 1), \"distance2\"\n",
    "    ]\n",
    "    df.loc[(df.label_hunt1 == 1) & (df.label_hunt2.isnull()), \"combine_dis\"] = df.loc[\n",
    "        (df.label_hunt1 == 1) & (df.label_hunt2.isnull()), \"distance1\"\n",
    "    ]\n",
    "    df.loc[\n",
    "        ((df.label_hunt1 == 1) & (df.label_hunt2 == 1))\n",
    "        | ((df.label_hunt1.isnull()) & (df.label_hunt2.isnull())),\n",
    "        \"combine_dis\",\n",
    "    ] = df.loc[\n",
    "        ((df.label_hunt1 == 1) & (df.label_hunt2 == 1))\n",
    "        | ((df.label_hunt1.isnull()) & (df.label_hunt2.isnull())),\n",
    "        [\"distance2\", \"distance1\"],\n",
    "    ].min(\n",
    "        1\n",
    "    )\n",
    "\n",
    "    \"\"\"比例\"\"\"\n",
    "    bincut = 2\n",
    "    df_plot = df[\n",
    "        (df[\"rwd_pac_distance\"] > 0) & (df.status_h1 <= 1) & (df.status_h2 <= 1)\n",
    "    ].pivot_table(\n",
    "        columns=np.ceil(df[\"rwd_pac_distance\"] / bincut) * bincut,\n",
    "        index=np.ceil(df[\"combine_dis\"] / bincut) * bincut,\n",
    "        values=\"combine_hunt\",\n",
    "        aggfunc=lambda x: sum(x == 1) / len(x) if len(x) > 3 else np.nan,\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = sns.heatmap(\n",
    "        df_plot.reindex(range(0, 38, bincut)).T.reindex(range(0, 30, bincut)).T,\n",
    "        square=True,\n",
    "        cmap=\"coolwarm\",\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cbar_kws={\"shrink\": 0.7},\n",
    "    )\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticklabels(\n",
    "        [i.get_text().split(\".\")[0] for i in ax.get_xticklabels()], rotation=0\n",
    "    )\n",
    "    ax.set_yticklabels([i.get_text().split(\".\")[0] for i in ax.get_yticklabels()])\n",
    "    ax.set_ylabel(\"P-G Distance\")\n",
    "    ax.set_xlabel(\"P-Nearest B Distance\")\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_ticks([0, 1])\n",
    "    cbar.set_ticklabels([0, 1])\n",
    "    b, t = plt.ylim()  # discover the values for bottom and top\n",
    "    plt.ylim(b - 0.5, t + 0.5)  # update the ylim(bottom, top) values\n",
    "    ax.figure.savefig(\"../\" + name + \"pics/4B2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_4B2(\n",
    "    df_total,\n",
    "    map_indexes_plan\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图4C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_4C5C(df_total, mapping, save_name, name=\"overall\"):\n",
    "    l = []\n",
    "    for i in [\n",
    "        \"pacman_sacc\",\n",
    "        \"ghost1Pos_sacc\",\n",
    "        \"ghost2Pos_sacc\",\n",
    "    ]:\n",
    "\n",
    "        for key, sel_index in mapping.items():\n",
    "            sacc_per = [df_total.loc[s[-7:], i].sum() / 3 for s in sel_index]\n",
    "            l.append(\n",
    "                [\n",
    "                    i.split(\"_\")[0],\n",
    "                    np.mean(sacc_per),\n",
    "                    np.std(sacc_per) / np.sqrt(len(sacc_per)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    df_plot = pd.DataFrame(l, columns=[\"agent\", \"mean\", \"std\"]).assign(\n",
    "        status=list(mapping.keys()) * 3\n",
    "    )\n",
    "    ax = (\n",
    "        df_plot.pivot(index=\"agent\", columns=\"status\", values=\"mean\")\n",
    "        .loc[:, ::-1]\n",
    "        .plot(\n",
    "            kind=\"bar\",\n",
    "            yerr=df_plot.pivot(index=\"agent\", columns=\"status\", values=\"std\").values.T,\n",
    "            color=plt.cm.Set1.colors[:2][::-1],\n",
    "        )\n",
    "    )\n",
    "    plt.ylabel(\"Average saccade frequency\")\n",
    "    plt.xlabel(\"saccade subject\")\n",
    "    plt.legend(title=None)\n",
    "    ax.set_xticklabels([\"Ghost Blinky\", \"Ghost Clyde\", \"PacMan Self\"], rotation=0)\n",
    "    plt.savefig(\"../\" + name + \"pics/\" + save_name + \".pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 686225\n",
    "plot_4C5C(\n",
    "    df_total,\n",
    "    {\n",
    "        \"Planned Attack\": cons_list_plan.values,\n",
    "        \"Accidental Attack\": cons_list_accident.values,\n",
    "    },\n",
    "    \"4C\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图4C3-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_4D(df_total, cons_list_accident, cons_list_plan):\n",
    "    sns.set_palette(\n",
    "        [\n",
    "            \"green\",\n",
    "            \"firebrick\",\n",
    "            \"khaki\",\n",
    "            \"PaleTurquoise\",\n",
    "            \"red\",\n",
    "            \"orange\",\n",
    "            \"pink\",\n",
    "            \"grey\",\n",
    "        ]\n",
    "    )\n",
    "    cnt = 3\n",
    "    for state in [\"accidentally\", \"planned\"]:\n",
    "        fig, ax = plt.subplots(dpi=300)\n",
    "        if state == \"accidentally\":\n",
    "            sel_df = df_total.loc[\n",
    "                df_total.index.isin(list(itertools.chain(*cons_list_accident)))\n",
    "            ]\n",
    "        else:\n",
    "            sel_df = df_total.loc[\n",
    "                df_total.index.isin(list(itertools.chain(*cons_list_plan)))\n",
    "            ]\n",
    "        pd.DataFrame(\n",
    "            sel_df[\n",
    "                [\n",
    "                    \"pacman_sacc\",\n",
    "                    \"ghost1Pos_sacc\",\n",
    "                    \"ghost2Pos_sacc\",\n",
    "                    \"beans_sacc\",\n",
    "                    \"energizer_sacc\",\n",
    "                    \"for_sacc\",\n",
    "                    \"back_sacc\",\n",
    "                    \"wandering\",\n",
    "                ]\n",
    "            ]\n",
    "            .fillna(False)\n",
    "            .mean()\n",
    "        ).T.plot(kind=\"bar\", ax=ax)\n",
    "        ax.set_xticklabels([\"\"], rotation=0)\n",
    "        ax.set_ylabel(\"saccade ratio\")\n",
    "        plt.legend(\n",
    "            [\n",
    "                \"pacman\",\n",
    "                \"ghost1\",\n",
    "                \"ghost2\",\n",
    "                \"beans\",\n",
    "                \"energizer\",\n",
    "                \"forward\",\n",
    "                \"backward\",\n",
    "                \"wandering\",\n",
    "            ],\n",
    "            ncol=1\n",
    "        )\n",
    "        plt.ylim(0, 0.5)\n",
    "#         plt.legend(ncol=2)\n",
    "        plt.title(state)\n",
    "        plt.savefig(\"../overallpics/4C\" + str(cnt) + \".pdf\")\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_4D(df_total, cons_list_accident, cons_list_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_4D(df_total, index_mapping, name):\n",
    "    if \"base1\" not in df_total.columns:\n",
    "        df_total = add_possible_dirs(df_total)\n",
    "\n",
    "    rs_status = pd.concat(\n",
    "        [\n",
    "            toward_ghost_table(\n",
    "                df_total, df_total.index.isin(list(itertools.chain(*item)))\n",
    "            ).assign(label=key)\n",
    "            for key, item in index_mapping.items()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rs_status = rs_status[rs_status.status == \"normal\"]\n",
    "\n",
    "    mapping_d = {\"1\": \"red\", \"2\": \"yellow\"}\n",
    "    sns.set_palette(plt.cm.Set1.colors[:2])\n",
    "    for key in mapping_d.keys():\n",
    "        ghost_color = mapping_d[key]\n",
    "        f = plt.figure()\n",
    "        for idx, gpd in rs_status[\n",
    "            rs_status.ghost == \"ghost(\" + ghost_color + \")\"\n",
    "        ].groupby([\"label\"]):\n",
    "            plt.errorbar(\n",
    "                gpd[\"level_0\"],\n",
    "                gpd[\"mean\"],\n",
    "                yerr=gpd[\"std\"] / np.sqrt(gpd[\"count\"]),\n",
    "                marker=None,\n",
    "                capsize=3,\n",
    "                barsabove=True,\n",
    "                label=idx,\n",
    "            )\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"pacman - ghost distance\")\n",
    "        plt.ylabel(\"% of toward ghost\")\n",
    "        plt.title(\n",
    "            \"pacman's move diminishes manhat. distance of pacman-ghost \\n(\"\n",
    "            + ghost_color\n",
    "            + \" ghost)\",\n",
    "        )\n",
    "        plt.ylim(0, 1)\n",
    "        f.savefig(\"../\" + name + \"pics/4D\" + ghost_color + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_mapping = {\n",
    "    \"accidental attack\": cons_list_accident,\n",
    "    \"planned attack\": cons_list_plan,\n",
    "}\n",
    "plot_4D(df_total, index_mapping, \"simulated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图4E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt_before_after_eye(last_index_list, df_total, rt, cutoff, col, cond_col=None):\n",
    "    after_df, before_df = pd.DataFrame(), pd.DataFrame()\n",
    "    for i in last_index_list:\n",
    "        file, index = df_total.loc[i, \"file\"], df_total.loc[i, \"index\"]\n",
    "        before = rt[(rt.file == file) & (rt[\"index\"] < index)].iloc[-cutoff:][\n",
    "            [col, cond_col]\n",
    "        ]\n",
    "        before = before[col].mask(before[cond_col] == 0)\n",
    "        before = pd.Series(before.values, index=range(before.shape[0], 0, -1))\n",
    "        before_df = pd.concat([before_df, before], 1)\n",
    "\n",
    "        after = rt[(rt.file == file) & (rt[\"index\"] > index)].iloc[:cutoff][\n",
    "            [col, cond_col]\n",
    "        ]\n",
    "        after = after[col].mask(after[cond_col] == 0)\n",
    "        after = pd.Series(after.values, index=range(1, after.shape[0] + 1))\n",
    "        after_df = pd.concat([after_df, after], 1)\n",
    "    return after_df, before_df\n",
    "\n",
    "\n",
    "def plot_4E(\n",
    "    df_total,\n",
    "    cons_list_accident,\n",
    "    map_indexes_accident,\n",
    "    cons_list_plan,\n",
    "    map_indexes_plan,\n",
    "    name=\"overall\",\n",
    "):\n",
    "    accident_all = combine_pre_post(cons_list_accident, map_indexes_accident)\n",
    "    prehunt_all = combine_pre_post(cons_list_plan, map_indexes_plan)\n",
    "\n",
    "    sns.set_palette(plt.cm.Set1.colors[:2][::-1])\n",
    "    cutoff = 10\n",
    "    for compute_list in [prehunt_all, accident_all]:\n",
    "        after_df, before_df = rt_before_after_eye(\n",
    "            [\n",
    "                i[-1]\n",
    "                for i in compute_list\n",
    "                if max(df_total.loc[i[-1] + 1, [\"ifscared1\", \"ifscared2\"]] == 3)\n",
    "            ],\n",
    "            df_total,\n",
    "            df_total,\n",
    "            cutoff,\n",
    "            \"eye_size_std2\",\n",
    "            cond_col=\"eye_size\",\n",
    "        )\n",
    "        after_sts = pd.DataFrame(\n",
    "            {\n",
    "                \"mean\": after_df.mean(1).values,\n",
    "                \"std\": after_df.std(1).values,\n",
    "                \"count\": after_df.count(1).values,\n",
    "            },\n",
    "            index=range(1, cutoff + 1),\n",
    "        )\n",
    "        before_sts = pd.DataFrame(\n",
    "            {\n",
    "                \"mean\": before_df.mean(1).values,\n",
    "                \"std\": before_df.std(1).values,\n",
    "                \"count\": before_df.count(1).values,\n",
    "            },\n",
    "            index=range(-1, -cutoff - 1, -1),\n",
    "        )\n",
    "        df_plot = before_sts.append(after_sts).sort_index()\n",
    "        plt.errorbar(\n",
    "            df_plot.index,\n",
    "            df_plot[\"mean\"],\n",
    "            yerr=df_plot[\"std\"] / np.sqrt(df_plot[\"count\"]),\n",
    "            marker=None,\n",
    "            capsize=3,\n",
    "            barsabove=True,\n",
    "        )\n",
    "    #     plt.xticks(df_plot.index[::2], [round(i * 25 / 60, 2) for i in df_plot.index[::2]])\n",
    "    plt.ylabel(\"relative pupil size\")\n",
    "    plt.xlabel(\"seconds before or after eat ghost\")\n",
    "    plt.legend([\"planned attack\", \"accidental attack\"])\n",
    "    plt.savefig(\"../\" + name + \"pics/4E.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 686225\n",
    "plot_4E(\n",
    "    df_total[df_total.file.str.contains(\"-\")],\n",
    "    cons_list_accident.apply(lambda x: x if x[-1] < 10e10 else np.nan).dropna().values,\n",
    "    map_indexes_accident.apply(lambda x: x if x[-1] < 10e10 else np.nan)\n",
    "    .dropna()\n",
    "    .values,\n",
    "    cons_list_plan.apply(lambda x: x if x[-1] < 10e10 else np.nan).dropna().values,\n",
    "    map_indexes_plan.apply(lambda x: x if x[-1] < 10e10 else np.nan).dropna().values,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图5A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_suicide_normal(df_total):\n",
    "    select_last_num = 100\n",
    "    suicide_normal = (\n",
    "        df_total.reset_index()\n",
    "        .merge(\n",
    "            (df_total.groupby(\"file\")[\"label_suicide\"].sum() > 0)\n",
    "            .rename(\"suicide_trial\")\n",
    "            .reset_index(),\n",
    "            on=\"file\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .sort_values(by=\"level_0\")\n",
    "        .groupby([\"file\", \"suicide_trial\"])\n",
    "        .apply(lambda x: x.level_0.tail(select_last_num).tolist())\n",
    "        .reset_index()\n",
    "    )\n",
    "    suicide_lists = suicide_normal[suicide_normal[\"suicide_trial\"] == True][0]\n",
    "    normal_lists = suicide_normal[suicide_normal[\"suicide_trial\"] == False][0]\n",
    "    return suicide_lists, normal_lists\n",
    "\n",
    "\n",
    "def plot_5A1(df_total, suicide_lists, normal_lists, name=\"overall\"):\n",
    "    sns.set_palette(plt.cm.Set1.colors[:2][::-1])\n",
    "    plt.subplots()\n",
    "    for compute_list in [suicide_lists, normal_lists]:\n",
    "        i = 2\n",
    "        data = pd.Series(\n",
    "            [\n",
    "                df_total.loc[j[-i], \"eye_size_std2\"]\n",
    "                for j in compute_list\n",
    "                if i <= len(j) and df_total.loc[j[-i], \"eye_size\"] != 0\n",
    "            ]\n",
    "        )\n",
    "        data.hist(\n",
    "            bins=range(-2000, 2000, 100),\n",
    "            alpha=0.7,\n",
    "            weights=np.ones(data.shape[0]) / data.shape[0],\n",
    "        )\n",
    "        plt.grid(False)\n",
    "        plt.legend([\"suicide\", \"normal die\"])\n",
    "        plt.xlabel(\"pupil size - average pupil size per trial\")\n",
    "        plt.ylabel(\"normalized count\")\n",
    "        plt.xlim(-2000, 2000)\n",
    "    plt.savefig(\"../\" + name + \"pics/5A1histogram.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    xaxis = range(10, 1, -1)\n",
    "    sns.set_palette(plt.cm.Set1.colors[:2][::-1])\n",
    "    plt.subplots()\n",
    "    for compute_list in [suicide_lists, normal_lists]:\n",
    "        data = [\n",
    "            [\n",
    "                df_total.loc[j[-i], \"eye_size_std2\"]\n",
    "                for j in compute_list\n",
    "                if i <= len(j) and df_total.loc[j[-i], \"eye_size\"] != 0\n",
    "            ]\n",
    "            for i in xaxis\n",
    "        ]\n",
    "        gpd = pd.DataFrame(\n",
    "            [[np.mean(i), np.std(i), len(i)] for i in data],\n",
    "            columns=[\"mean\", \"std\", \"count\"],\n",
    "        )\n",
    "        gpd.index = [round(-(i - 1) * 25 / 60, 2) for i in xaxis]\n",
    "        plt.errorbar(\n",
    "            gpd.index,\n",
    "            gpd[\"mean\"],\n",
    "            yerr=gpd[\"std\"] / np.sqrt(gpd[\"count\"]),\n",
    "            marker=None,\n",
    "            capsize=3,\n",
    "            barsabove=True,\n",
    "        )\n",
    "    plt.legend([\"suicide\", \"normal die\"])\n",
    "    plt.ylabel(\"relative pupil size\")\n",
    "    plt.xlabel(\"time before getting caught\")\n",
    "    plt.savefig(\"../\" + name + \"pics/5A1line.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suicide_lists, normal_lists = generate_suicide_normal(df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_5A1(\n",
    "    df_total, suicide_lists, normal_lists,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图5A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_5A2(df_total, suicide_lists, normal_lists):\n",
    "    xaxis = range(1, 15)\n",
    "    sns.set_palette(plt.cm.Set1.colors[:2][::-1])\n",
    "    if \"rt_std\" not in df_total.columns:\n",
    "        df_total = df_total.merge(\n",
    "            rt[[\"file\", \"index\", \"rt\", \"rt_std\"]], on=[\"file\", \"index\"], how=\"left\"\n",
    "        )\n",
    "    for compute_list in [suicide_lists, normal_lists]:\n",
    "        data = [\n",
    "            [\n",
    "                df_total.loc[j, \"rt_std\"].dropna().values[-i]\n",
    "                for j in compute_list\n",
    "                if df_total.loc[j, \"rt_std\"].dropna().shape[0] >= i\n",
    "            ]\n",
    "            for i in xaxis\n",
    "        ]\n",
    "        gpd = pd.DataFrame(\n",
    "            [[np.mean(i), np.std(i), len(i)] for i in data],\n",
    "            columns=[\"mean\", \"std\", \"count\"],\n",
    "        )\n",
    "        gpd.index = [-i for i in xaxis]\n",
    "        plt.errorbar(\n",
    "            gpd.index,\n",
    "            gpd[\"mean\"],\n",
    "            yerr=gpd[\"std\"] / np.sqrt(gpd[\"count\"]),\n",
    "            marker=None,\n",
    "            capsize=3,\n",
    "            barsabove=True,\n",
    "        )\n",
    "    # set_trace()\n",
    "    plt.legend([\"suicide\", \"normal die\"])\n",
    "    plt.xlabel(\"# RT to the final point\")\n",
    "    plt.ylabel(\"average RT\")\n",
    "    plt.savefig(\"../overallpics/5A2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_5A2(df_total, suicide_lists, normal_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_5B(df_total, name=\"overall\"):\n",
    "    plt.tight_layout()\n",
    "    evade_indexes = (\n",
    "        df_total[df_total.status == \"pessimistic_record\"]\n",
    "        .groupby(\"file\")\n",
    "        .apply(lambda x: x.index.tolist()[0])\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    df_temp = (\n",
    "        add_dis(\n",
    "            df_total.loc[evade_indexes, :].reset_index(),\n",
    "            \"next_eat_rwd_fill\",\n",
    "            \"pacmanPos\",\n",
    "        )\n",
    "        .set_index(\"level_0\")\n",
    "        .sort_index()\n",
    "        .dis\n",
    "    )\n",
    "\n",
    "    df1 = df_total.loc[evade_indexes, :]\n",
    "    df1[\"resetpos\"] = [(14, 27)] * df1.shape[0]\n",
    "\n",
    "    df_temp_re = (\n",
    "        add_dis(df1.reset_index(), \"resetpos\", \"next_eat_rwd_fill\")\n",
    "        .set_index(\"level_0\")\n",
    "        .sort_index()\n",
    "        .dis\n",
    "    )\n",
    "\n",
    "    suicide_start_index = (\n",
    "        df_total[df_total.status == \"suicide_record\"]\n",
    "        .groupby(\"file\")\n",
    "        .apply(lambda x: x.index.tolist()[0])\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    df_com = df_total.loc[suicide_start_index, :].rename(\n",
    "        columns={\"rwd_reset_distance\": \"reset_dis\", \"pacman_reset_dis\": \"suicide_dis\"}\n",
    "    )\n",
    "\n",
    "    df_hist_suicide = (\n",
    "        pd.cut(\n",
    "            df_com.suicide_dis - df_com.reset_dis,\n",
    "            bins=range(-38, 30, 2),\n",
    "            labels=range(-36, 30, 2),\n",
    "        )\n",
    "        .value_counts(normalize=True)\n",
    "        .rename(\"distance\")\n",
    "        .reset_index()\n",
    "        .assign(category=\"suicide\")\n",
    "    )\n",
    "    \"\"\"\n",
    "    开始画图\n",
    "    \"\"\"\n",
    "    df_hist_suicide.category = \"suicide > 0 ratio: \" + str(\n",
    "        round(df_hist_suicide[df_hist_suicide[\"index\"] > 0].sum().distance, 2)\n",
    "    )\n",
    "    df_hist_evade = (\n",
    "        pd.cut(df_temp - df_temp_re, bins=range(-38, 30, 2), labels=range(-36, 30, 2))\n",
    "        .value_counts(normalize=True)\n",
    "        .rename(\"distance\")\n",
    "        .reset_index()\n",
    "        .assign(category=\"evade\")\n",
    "    )\n",
    "    df_hist_evade.category = \"evade > 0 ratio: \" + str(\n",
    "        round(df_hist_evade[df_hist_evade[\"index\"] > 0].sum().distance, 2)\n",
    "    )\n",
    "\n",
    "    sns.set_palette(plt.cm.Set1.colors[:2])\n",
    "    ax = sns.barplot(\n",
    "        data=pd.concat([df_hist_evade, df_hist_suicide]).sort_values(by=\"index\"),\n",
    "        x=\"index\",\n",
    "        y=\"distance\",\n",
    "        hue=\"category\",\n",
    "    )\n",
    "    #     set_trace()\n",
    "    ax.vlines(\n",
    "        x=(df_temp - df_temp_re).mean() / 2 + 18,\n",
    "        ymin=0,\n",
    "        ymax=0.12,\n",
    "        linestyle=\"--\",\n",
    "        color=plt.cm.Set1.colors[0],\n",
    "    )\n",
    "    ax.vlines(\n",
    "        x=(df_com.suicide_dis - df_com.reset_dis).mean() / 2 + 18,\n",
    "        ymin=0,\n",
    "        ymax=0.18,\n",
    "        linestyle=\"--\",\n",
    "        color=plt.cm.Set1.colors[1],\n",
    "    )\n",
    "    plt.legend(title=None)\n",
    "    plt.ylim(0, 0.2)\n",
    "    tks, labels = ax.get_xticks(), [i.get_text() for i in ax.get_xticklabels()]\n",
    "    ax.set_xticks(tks[::4])\n",
    "    ax.set_xticklabels(labels[::4])\n",
    "    ax.set_xlabel(\"(Pacman-Pellet Distance) - (Reset-Pellet Distance)\")\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.figure.savefig(\"../\" + name + \"pics/5B.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "添加reset位置最近的点\n",
    "添加next_eat_rwd_fill这个字段\n",
    "\"\"\"\n",
    "df_total_small = add_nearest_rwd_reset(\n",
    "    df_total_small.reset_index()\n",
    "    .groupby(\"file\")\n",
    "    .apply(\n",
    "        lambda x: x.assign(\n",
    "            next_eat_rwd_fill=x.next_eat_rwd.fillna(method=\"bfill\")\n",
    "        ).drop(\"file\", 1)\n",
    "    )\n",
    "    .reset_index()\n",
    "    .drop(\"level_1\", 1)\n",
    "    .set_index(\"level_0\")\n",
    "    .sort_index()\n",
    ")\n",
    "df_total_small[\"pacman_reset_dis\"] = (\n",
    "    add_dis(\n",
    "        df_total_small[[\"nearresetPos\", \"pacmanPos\"]]\n",
    "        .explode(\"nearresetPos\")\n",
    "        .reset_index(),\n",
    "        \"nearresetPos\",\n",
    "        \"pacmanPos\",\n",
    "    )\n",
    "    .sort_values(\"dis\")\n",
    "    .groupby(\"index\")\n",
    "    .first()\n",
    "    .dis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plot_5B(df_total_small, name=\"simulated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_4C5C(\n",
    "    df_total[df_total.file.str.contains(\"Patamon\")],\n",
    "    {\n",
    "        \"Suicide\": suicide_lists.apply(lambda x: x if x[0] >= 686225 else np.nan)\n",
    "        .dropna()\n",
    "        .values,\n",
    "        \"Normal Die\": normal_lists.apply(lambda x: x if x[0] >= 686225 else np.nan)\n",
    "        .dropna()\n",
    "        .values,\n",
    "    },\n",
    "    \"5C\",\n",
    "    \"patamon\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图5C3-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3B5C(df_total, [\"evade\", \"suicide\"], '5C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图5D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_5d(df_total, name=\"overall\"):\n",
    "    games = (\n",
    "        df_total[[\"game\", \"game_trial\"]]\n",
    "        .drop_duplicates()\n",
    "        .groupby(\"game\")\n",
    "        .count()\n",
    "        .apply(lambda x: x.game_trial if x.game_trial >= 6 else np.nan, 1)\n",
    "        .dropna()\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    ratios = (\n",
    "        df_total[df_total.game.isin(games)]\n",
    "        .groupby(\"game_trial\")\n",
    "        .apply(lambda x: x.groupby(\"file\").label_suicide.max().fillna(0).mean())\n",
    "    )\n",
    "\n",
    "    ratios.index = ratios.index.astype(int)\n",
    "    ratios.sort_index().plot(marker=\"o\")\n",
    "    plt.xlabel(\"trial number\")\n",
    "    plt.ylabel(\"suicide ratio\")\n",
    "    plt.savefig(\"../\" + name + \"pics/5D.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_5d(df_total[df_total.file.str.contains(\"Patamon\")], \"patamon\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "554px",
    "left": "767px",
    "right": "20px",
    "top": "122px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}